{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "We create a set of *boards* of size $5 \\times 5$ with 3 channels for each position. The label at each position $(j,k)$ is computed as a function of the channel values $v_{jkl}$ at that position.\n",
    "\n",
    "$$\n",
    "    L_{jk} = \\sum_{l=0}^2 a_l \\cdot (v_{jkl})^{l+1}\n",
    "$$\n",
    "\n",
    "Here, $a_l$ denote arbitrary coefficients defined below. Note that this function is the same for every position. Thus, a sufficiently deep convolutional network with only $1 \\times 1$ kernels should easily learn this function by simultaneously looking at all the positions of any given training board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(N):\n",
    "    batch = np.zeros([N,5,5,3])\n",
    "    labels = np.zeros([N,5,5,1])\n",
    "    a=[.9, .3, -.2]\n",
    "    for i in range(N):\n",
    "        for x in range(5):\n",
    "            for y in range(5):\n",
    "                for l in range(3):\n",
    "                    v = 2*(random.random()-0.5)\n",
    "                    batch[i][x][y][l] = v\n",
    "                    labels[i][x][y][0] += a[l] * v**(l+1)\n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "batch, labels = create_data(N)\n",
    "batch_t, labels_t = create_data(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smartly rearranging the dimensions of the first *board* of the batch shows the three $5 \\times 5$ channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.rollaxis(batch[0], 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = tf.placeholder(tf.float32, [None, 5, 5, 3])\n",
    "_labels = tf.placeholder(tf.float32, [None, 5, 5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A special CNN\n",
    "The convolutional network below can actually be regarded as a single convolutional layer with the kernel itself being a 5-layer feed-forward NN with layers $[3, 8, 32, 32, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=_inputs, filters=32, kernel_size=[1,1], strides=[1,1], padding='VALID', activation=tf.nn.elu)\n",
    "conv2 = tf.layers.conv2d(inputs=conv1, filters=128, kernel_size=[1,1], strides=[1,1], padding='VALID', activation=tf.nn.elu)\n",
    "conv3 = tf.layers.conv2d(inputs=conv2, filters=32, kernel_size=[1,1], strides=[1,1], padding='VALID', activation=tf.nn.elu)\n",
    "conv4 = tf.layers.conv2d(inputs=conv3, filters=1, kernel_size=[1,1], strides=[1,1], padding='VALID')\n",
    "\n",
    "loss = tf.losses.mean_squared_error(_labels,conv4)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "We train the network and compute training loss and test loss once in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for i in range(3001):\n",
    "        _ = session.run(optimizer, feed_dict={_inputs: batch, _labels: labels})\n",
    "        if i % 1000 == 0:\n",
    "            l = session.run(loss, feed_dict={_inputs: batch, _labels: labels})\n",
    "            l_t = session.run(loss, feed_dict={_inputs: batch_t, _labels: labels_t})\n",
    "            print(l, l_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the smooth convergence also on the test set we can see that the network has indeed learned our label function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
