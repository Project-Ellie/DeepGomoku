{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train the contender on self-play episodes of the champion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "from alphazero.mcts import MCTS\n",
    "from alphazero.coach import Coach\n",
    "from alphazero.gomoku_game import GomokuGame as Gomoku, initial_stones\n",
    "from alphazero.interfaces import TrainParams\n",
    "from domoku.policies.heuristic_policy import HeuristicPolicy\n",
    "from alphazero.gomoku_board import GomokuBoard\n",
    "from domoku import tools as gt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BOARD_SIZE = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 19:49:20.506239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/wgiersche/.local/share/virtualenvs/DeepGomoku-cXtJ_EtM/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "detector = HeuristicPolicy(BOARD_SIZE, cut_off=.1)\n",
    "game = Gomoku(BOARD_SIZE, detector=detector, initial=initial_stones(BOARD_SIZE, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wgiersche/.local/share/virtualenvs/DeepGomoku-cXtJ_EtM/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "policy = HeuristicPolicy(BOARD_SIZE, cut_off=.1)\n",
    "mcts = MCTS(game, policy, cpuct=1.0, num_simulations=100, model_threshold=.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K6 K12 L10 K4 (Black next)\n",
      "K6 K12 L10 K4 K7 (White next)\n",
      "K6 K12 L10 K4 K7 J8 (Black next)\n",
      "K6 K12 L10 K4 K7 J8 K9 (White next)\n",
      "K6 K12 L10 K4 K7 J8 K9 K8 (Black next)\n",
      "... K12 L10 K4 K7 J8 K9 K8 L8 (White next)\n",
      "... L10 K4 K7 J8 K9 K8 L8 L9 (Black next)\n",
      "... K4 K7 J8 K9 K8 L8 L9 J6 (White next)\n",
      "... K7 J8 K9 K8 L8 L9 J6 I5 (Black next)\n",
      "... J8 K9 K8 L8 L9 J6 I5 M6 (White next)\n",
      "... K9 K8 L8 L9 J6 I5 M6 L6 (Black next)\n",
      "... K8 L8 L9 J6 I5 M6 L6 M9 (White next)\n",
      "... L8 L9 J6 I5 M6 L6 M9 N10 (Black next)\n",
      "... L9 J6 I5 M6 L6 M9 N10 M7 (White next)\n",
      "... J6 I5 M6 L6 M9 N10 M7 N6 (Black next)\n",
      "... I5 M6 L6 M9 N10 M7 N6 M8 (White next)\n",
      "... M6 L6 M9 N10 M7 N6 M8 M10 (Black next)\n",
      "... L6 M9 N10 M7 N6 M8 M10 M5 (White next)\n",
      "The winner is 0\n",
      "                                                     \n",
      "15    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "14    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "13    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "12    .  .  .  .  .  .  .  .  .  .  O  .  .  .  .    \n",
      "11    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "10    .  .  .  .  .  .  .  .  .  .  .  X  O  O  .    \n",
      " 9    .  .  .  .  .  .  .  .  .  .  X  O  X  .  .    \n",
      " 8    .  .  .  .  .  .  .  .  .  O  O  X  X  .  .    \n",
      " 7    .  .  .  .  .  .  .  .  .  .  X  .  X  .  .    \n",
      " 6    .  .  .  .  .  .  .  .  .  X  X  O  X  O  .    \n",
      " 5    .  .  .  .  .  .  .  .  O  .  .  . [X] .  .    \n",
      " 4    .  .  .  .  .  .  .  .  .  .  O  .  .  .  .    \n",
      " 3    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      " 2    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      " 1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "                                                     \n",
      "      A  B  C  D  E  F  G  H  I  J  K  L  M  N  O\n"
     ]
    }
   ],
   "source": [
    "board = game.get_initial_board()  # random start positions, sometimes unfair, but so what?\n",
    "print(board)\n",
    "import numpy as np\n",
    "\n",
    "# Two mood versions of the champion playing against each other = less draws\n",
    "# These settings may change over the training period, once opponents get stronger.\n",
    "temperatures = [0.4, 0]  # more tight vs more explorative\n",
    "\n",
    "episode_step = 0\n",
    "train_examples = []\n",
    "done = policy.get_winner(board.canonical_representation())\n",
    "while done is None:\n",
    "    episode_step += 1\n",
    "    t = temperatures[episode_step % 2]\n",
    "    pi = mcts.get_action_prob(board, temperature=t)\n",
    "    action = np.random.choice(len(pi), p=pi)\n",
    "    board.act(action)\n",
    "    print(board)\n",
    "    done = policy.get_winner(board.canonical_representation())\n",
    "\n",
    "# The player who made the last move, is the winner.\n",
    "print (f\"The winner is {1-board.get_current_player()}\")\n",
    "board.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from domoku.board import GomokuBoard as LegacyBoard\n",
    "board = deepcopy(board)\n",
    "stones = board.stones [:-10]\n",
    "stones = \"\".join([str(stone) for stone in stones])\n",
    "board_t = LegacyBoard(n=BOARD_SIZE, disp_width=8, stones=stones, heuristics=policy)\n",
    "board_t.display()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For reference: The policy's opinion about that board state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   8   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   8   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  17   0   8   8   0  27   0]\n",
      " [  0   0   0   0   0   0   0   0   8  17   8   0  35   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 307   8   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8   0  35   0   8  18   8   0]\n",
      " [  0   0   0   0   0   0   0  18  45   0   0  18  18  17   0]\n",
      " [  0   0   0   0   0   0   0   0 307   9   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   8   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Value: -0.12350778981345308\n"
     ]
    }
   ],
   "source": [
    "board = GomokuBoard(BOARD_SIZE, stones)\n",
    "pi, v = policy(board.canonical_representation())\n",
    "print((np.array(pi)*1000).astype(int))\n",
    "print(f\"Value: {v}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The search tree has a similar yet more ascertive opinion\n",
    "The action counts will inform the next policy and the $max(Q_a)$ may inform the value function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In most cases, the softmax will agree with the move actually taken, only if the chances are somewhat equally distributed, will the softmax also allow for a choice."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 56  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Value from max(Q): -0.07781051466605755\n"
     ]
    }
   ],
   "source": [
    "key = board.get_string_representation()\n",
    "probs = mcts.compute_probs(board, temperature=1.0)\n",
    "probs = np.array(probs).reshape([BOARD_SIZE, BOARD_SIZE])\n",
    "print((probs*100).astype(int))\n",
    "q_advice = [mcts.Q.get((key, i), -float('inf')) for i in range(225)]\n",
    "print()\n",
    "print(f\"Value from max(Q): {np.max(q_advice)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Symmetries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "(17, 17, 3)"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_rep = board.canonical_representation()\n",
    "symmetries = game.get_symmetries(math_rep, probs)\n",
    "symmetries[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see the board diagonally flipped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (17, 17, 3)\n",
      "[[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 2 1 2 0 0 0 0 0 3]\n",
      " [3 0 0 0 1 0 2 2 1 2 0 0 1 0 0 0 3]\n",
      " [3 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "gt.print_channels(symmetries[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 56  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 40  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print((np.array(symmetries[i][1]).reshape(15, 15) * 100).astype(int))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Training\n",
    "\n",
    "Would be nice to see the training converge (and overfit) with a single episode in its 8 symmetries, and validate the overfitted against a board with all stones shifted. We'd expect only minor differences due to the different border influence, but otherwise the conv-only network naturally features translation symmetry."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "from alphazero.gomoku_model import NeuralNetAdapter, GomokuModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "the_model = NeuralNetAdapter(BOARD_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1, 225), dtype=float32, numpy=\n array([[0.00306087, 0.00466489, 0.00555502, 0.00306087, 0.00388482,\n         0.00627402, 0.00462206, 0.00490964, 0.00306087, 0.00306087,\n         0.00306087, 0.00527334, 0.00321493, 0.00385122, 0.00512841,\n         0.0030836 , 0.00348671, 0.00306087, 0.00406948, 0.00306087,\n         0.00306087, 0.00306087, 0.00306087, 0.00360089, 0.00354148,\n         0.00362952, 0.00327728, 0.00306087, 0.00369778, 0.00411889,\n         0.00316246, 0.00440491, 0.00306087, 0.0075722 , 0.00777036,\n         0.00513006, 0.00541622, 0.00704602, 0.00750286, 0.00742823,\n         0.00500624, 0.007187  , 0.0043631 , 0.00708181, 0.00718412,\n         0.00350399, 0.00388717, 0.00381796, 0.00306087, 0.0039538 ,\n         0.00306087, 0.00306087, 0.00789546, 0.00439931, 0.00306087,\n         0.00306087, 0.00496746, 0.00561695, 0.00588145, 0.00685185,\n         0.00306087, 0.00306087, 0.00583773, 0.00498733, 0.00716286,\n         0.00306087, 0.00306087, 0.0047185 , 0.00399803, 0.00366651,\n         0.00306087, 0.00424947, 0.00476933, 0.00626388, 0.00306087,\n         0.00306087, 0.00306087, 0.00311021, 0.00306087, 0.00638157,\n         0.00671898, 0.00306087, 0.00508141, 0.00630882, 0.00794181,\n         0.00306087, 0.00464398, 0.00712529, 0.00759878, 0.00638829,\n         0.00306087, 0.00572961, 0.00306087, 0.00306087, 0.00397385,\n         0.00306087, 0.00306087, 0.00306087, 0.00306087, 0.00526202,\n         0.00306087, 0.00306087, 0.00306087, 0.00310758, 0.00333787,\n         0.00306087, 0.00306087, 0.00306087, 0.00348972, 0.00543185,\n         0.00411354, 0.00306087, 0.00624287, 0.00662951, 0.00801336,\n         0.00306087, 0.00777164, 0.00562915, 0.00403836, 0.00353282,\n         0.00306087, 0.00306087, 0.00306087, 0.00306087, 0.00500504,\n         0.00306087, 0.00306087, 0.00651529, 0.00377205, 0.00693513,\n         0.00326682, 0.00306087, 0.00692361, 0.00488904, 0.00535668,\n         0.00482388, 0.00475069, 0.00675041, 0.00479973, 0.00306087,\n         0.00306087, 0.00602046, 0.00704659, 0.00306087, 0.00736164,\n         0.00594959, 0.0048521 , 0.00769666, 0.0037163 , 0.00306087,\n         0.00306087, 0.00306087, 0.00328648, 0.00560293, 0.00780383,\n         0.00306087, 0.00306087, 0.0068986 , 0.00306087, 0.00744271,\n         0.00645123, 0.00306087, 0.00678359, 0.00413228, 0.00384872,\n         0.00306087, 0.00306087, 0.00306087, 0.00306087, 0.00306087,\n         0.00435047, 0.00429299, 0.0074089 , 0.00647091, 0.00480969,\n         0.00403936, 0.00466833, 0.00765039, 0.00354448, 0.00358658,\n         0.00306087, 0.0041027 , 0.00465328, 0.00520094, 0.0037197 ,\n         0.00306087, 0.00548287, 0.00661768, 0.00402504, 0.00515832,\n         0.00754189, 0.00567193, 0.00656327, 0.00463235, 0.00583832,\n         0.00306087, 0.00306087, 0.00306087, 0.00582181, 0.00306087,\n         0.00306087, 0.00306087, 0.00306087, 0.00436412, 0.00427774,\n         0.0044337 , 0.00596456, 0.0063129 , 0.00357906, 0.0035583 ,\n         0.0040208 , 0.00306087, 0.00353039, 0.00306087, 0.00517436,\n         0.00306087, 0.00306087, 0.00306087, 0.00306087, 0.00306087,\n         0.00470059, 0.00624419, 0.004257  , 0.00306087, 0.00388482]],\n       dtype=float32)>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.9624098>)"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.predict(np.expand_dims(math_rep, axis=0).astype(float))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 17, 17, 3)"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(math_rep, axis=0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gomoku_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          multiple                  11648     \n",
      "                                                                 \n",
      " Potential_0 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_1 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_2 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_3 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_4 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          multiple                  10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 631,371\n",
      "Trainable params: 631,361\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "the_model.policy.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "params = TrainParams(\n",
    "    epochs_per_train=10,\n",
    "    update_threshold=0.6,\n",
    "    max_queue_length=8192,    # Number of game examples to keep to train the neural networks.\n",
    "    num_simulations=25,\n",
    "    arena_compare=2,         # Number of games to play during arena play to evaluate new network.\n",
    "    cpuct=1.0,\n",
    "    checkpoint_dir='./temperature/',\n",
    "    load_model=False,\n",
    "    load_folder_file=('/dev/models/8x100x50', 'best.pth.tar'),\n",
    "    num_iters_for_train_examples_history=4,\n",
    "    num_iterations=2,\n",
    "    num_episodes=2,\n",
    "    temperature_threshold=12\n",
    ")\n",
    "coach = Coach(game, params=params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "examples = coach.execute_episode(mcts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "120"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wgiersche/.local/share/virtualenvs/DeepGomoku-cXtJ_EtM/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "policy = HeuristicPolicy(BOARD_SIZE, cut_off=.1)\n",
    "mcts = MCTS(game, policy, cpuct=1.0, num_simulations=100, model_threshold=.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Self Play: 100%|██████████| 2/2 [04:22<00:00, 131.08s/it]\n"
     ]
    }
   ],
   "source": [
    "examples = coach.create_trajectories(mcts, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "496"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "ex = examples[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "(17, 17, 3)"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 2 1 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 3 7 2 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 2 5 0 2 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 3 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 2 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 2 3 3 2 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 3 3 3 2 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 2 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print((np.array(ex[1])*100).reshape((15, 15)).astype(int))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (17, 17, 3)\n",
      "[[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 1 0 0 2 1 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "gt.print_channels(ex[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Loss: 6.753357410430908\n",
      "Epoch: 1000, Loss: 6.750704765319824\n",
      "Epoch: 1000, Loss: 6.748652935028076\n",
      "Epoch: 1000, Loss: 6.744075775146484\n",
      "Epoch: 1000, Loss: 6.7397141456604\n",
      "Epoch: 1000, Loss: 6.736026763916016\n",
      "Epoch: 1000, Loss: 6.73242712020874\n",
      "Epoch: 1000, Loss: 6.72878360748291\n",
      "Epoch: 1000, Loss: 6.725214958190918\n",
      "Epoch: 1000, Loss: 6.7216997146606445\n",
      "Epoch: 1000, Loss: 6.718466281890869\n",
      "Epoch: 1000, Loss: 6.715295314788818\n",
      "Epoch: 1000, Loss: 6.712080001831055\n",
      "Epoch: 1000, Loss: 6.708822727203369\n",
      "Epoch: 1000, Loss: 6.70557975769043\n",
      "Epoch: 1000, Loss: 6.702432155609131\n",
      "Epoch: 1000, Loss: 6.699307441711426\n",
      "Epoch: 1000, Loss: 6.696255207061768\n",
      "Epoch: 1000, Loss: 6.693260192871094\n",
      "Epoch: 1000, Loss: 6.690584659576416\n",
      "Epoch: 1000, Loss: 6.689396381378174\n",
      "Epoch: 1000, Loss: 6.688157558441162\n",
      "Epoch: 1000, Loss: 6.6865692138671875\n",
      "Epoch: 1000, Loss: 6.685136795043945\n",
      "Epoch: 1000, Loss: 6.68588924407959\n",
      "Epoch: 1000, Loss: 6.686761856079102\n",
      "Epoch: 1000, Loss: 6.688048362731934\n",
      "Epoch: 1000, Loss: 6.688965797424316\n",
      "Epoch: 1000, Loss: 6.690290927886963\n",
      "Epoch: 1000, Loss: 6.690247535705566\n",
      "Epoch: 1000, Loss: 6.690465927124023\n",
      "Epoch: 1000, Loss: 6.690896987915039\n",
      "Epoch: 1000, Loss: 6.690925121307373\n",
      "Epoch: 1000, Loss: 6.690621852874756\n",
      "Epoch: 1000, Loss: 6.690194606781006\n",
      "Epoch: 1000, Loss: 6.689634323120117\n",
      "Epoch: 1000, Loss: 6.688895225524902\n",
      "Epoch: 1000, Loss: 6.687880039215088\n",
      "Epoch: 1000, Loss: 6.686672210693359\n",
      "Epoch: 1000, Loss: 6.685288429260254\n",
      "Epoch: 1000, Loss: 6.683785915374756\n",
      "Epoch: 1000, Loss: 6.682281494140625\n",
      "Epoch: 1000, Loss: 6.680776119232178\n",
      "Epoch: 1000, Loss: 6.679224014282227\n",
      "Epoch: 1000, Loss: 6.677610874176025\n",
      "Epoch: 1000, Loss: 6.67596960067749\n",
      "Epoch: 1000, Loss: 6.674311637878418\n",
      "Epoch: 1000, Loss: 6.672636032104492\n",
      "Epoch: 1000, Loss: 6.67095947265625\n",
      "Epoch: 1000, Loss: 6.66929817199707\n",
      "Epoch: 1000, Loss: 6.667647838592529\n",
      "Epoch: 1000, Loss: 6.666012763977051\n",
      "Epoch: 1000, Loss: 6.664400577545166\n",
      "Epoch: 1000, Loss: 6.66280460357666\n",
      "Epoch: 1000, Loss: 6.661228656768799\n",
      "Epoch: 1000, Loss: 6.659679412841797\n",
      "Epoch: 1000, Loss: 6.65815544128418\n",
      "Epoch: 1000, Loss: 6.65665864944458\n",
      "Epoch: 1000, Loss: 6.655183792114258\n",
      "Epoch: 1000, Loss: 6.653730392456055\n",
      "Epoch: 1000, Loss: 6.6523027420043945\n",
      "Epoch: 1000, Loss: 6.650900840759277\n",
      "Epoch: 1000, Loss: 6.64952278137207\n",
      "Epoch: 1000, Loss: 6.648167610168457\n",
      "Epoch: 1000, Loss: 6.646836757659912\n",
      "Epoch: 1000, Loss: 6.645529747009277\n",
      "Epoch: 1000, Loss: 6.64424467086792\n",
      "Epoch: 1000, Loss: 6.642982482910156\n",
      "Epoch: 1000, Loss: 6.6417412757873535\n",
      "Epoch: 1000, Loss: 6.640522003173828\n",
      "Epoch: 1000, Loss: 6.6393256187438965\n",
      "Epoch: 1000, Loss: 6.638154029846191\n",
      "Epoch: 1000, Loss: 6.637012004852295\n",
      "Epoch: 1000, Loss: 6.635897159576416\n",
      "Epoch: 1000, Loss: 6.634850978851318\n",
      "Epoch: 1000, Loss: 6.633763790130615\n",
      "Epoch: 1000, Loss: 6.632980823516846\n",
      "Epoch: 1000, Loss: 6.633998870849609\n",
      "Epoch: 1000, Loss: 6.636068344116211\n",
      "Epoch: 1000, Loss: 6.637978553771973\n",
      "Epoch: 1000, Loss: 6.639431953430176\n",
      "Epoch: 1000, Loss: 6.64047908782959\n",
      "Epoch: 1000, Loss: 6.6413397789001465\n",
      "Epoch: 1000, Loss: 6.641800880432129\n",
      "Epoch: 1000, Loss: 6.641958236694336\n",
      "Epoch: 1000, Loss: 6.641886234283447\n",
      "Epoch: 1000, Loss: 6.641720294952393\n",
      "Epoch: 1000, Loss: 6.641486644744873\n",
      "Epoch: 1000, Loss: 6.641188621520996\n",
      "Epoch: 1000, Loss: 6.640843391418457\n",
      "Epoch: 1000, Loss: 6.640448093414307\n",
      "Epoch: 1000, Loss: 6.639996528625488\n",
      "Epoch: 1000, Loss: 6.63950252532959\n",
      "Epoch: 1000, Loss: 6.638973236083984\n",
      "Epoch: 1000, Loss: 6.6384172439575195\n",
      "Epoch: 1000, Loss: 6.637833118438721\n",
      "Epoch: 1000, Loss: 6.637219429016113\n",
      "Epoch: 1000, Loss: 6.636582374572754\n",
      "Epoch: 1000, Loss: 6.635931491851807\n",
      "Epoch: 1000, Loss: 6.6352739334106445\n",
      "Epoch: 1000, Loss: 6.634605884552002\n",
      "Epoch: 1000, Loss: 6.633933067321777\n",
      "Epoch: 1000, Loss: 6.633254528045654\n",
      "Epoch: 1000, Loss: 6.632571697235107\n",
      "Epoch: 1000, Loss: 6.63188362121582\n",
      "Epoch: 1000, Loss: 6.631194114685059\n",
      "Epoch: 1000, Loss: 6.630504608154297\n",
      "Epoch: 1000, Loss: 6.629817485809326\n",
      "Epoch: 1000, Loss: 6.629131317138672\n",
      "Epoch: 1000, Loss: 6.628448009490967\n",
      "Epoch: 1000, Loss: 6.627768039703369\n",
      "Epoch: 1000, Loss: 6.627091884613037\n",
      "Epoch: 1000, Loss: 6.626420021057129\n",
      "Epoch: 1000, Loss: 6.6257524490356445\n",
      "Epoch: 1000, Loss: 6.625088214874268\n",
      "Epoch: 1000, Loss: 6.624428749084473\n",
      "Epoch: 1000, Loss: 6.623773574829102\n",
      "Epoch: 1000, Loss: 6.623123645782471\n",
      "Epoch: 1000, Loss: 6.622478008270264\n",
      "Epoch: 1000, Loss: 6.621838092803955\n",
      "Epoch: 1000, Loss: 6.62120246887207\n",
      "Epoch: 1000, Loss: 6.620573043823242\n",
      "Epoch: 1000, Loss: 6.619948863983154\n",
      "Epoch: 1000, Loss: 6.619329452514648\n",
      "Epoch: 1000, Loss: 6.618715763092041\n",
      "Epoch: 1000, Loss: 6.618107318878174\n",
      "Epoch: 1000, Loss: 6.617504119873047\n",
      "Epoch: 1000, Loss: 6.616906642913818\n",
      "Epoch: 1000, Loss: 6.61631441116333\n",
      "Epoch: 1000, Loss: 6.615728378295898\n",
      "Epoch: 1000, Loss: 6.615147590637207\n",
      "Epoch: 1000, Loss: 6.614572525024414\n",
      "Epoch: 1000, Loss: 6.6140031814575195\n",
      "Epoch: 1000, Loss: 6.613439083099365\n",
      "Epoch: 1000, Loss: 6.612880229949951\n",
      "Epoch: 1000, Loss: 6.612326145172119\n",
      "Epoch: 1000, Loss: 6.6117777824401855\n",
      "Epoch: 1000, Loss: 6.611233711242676\n",
      "Epoch: 1000, Loss: 6.6106953620910645\n",
      "Epoch: 1000, Loss: 6.610162258148193\n",
      "Epoch: 1000, Loss: 6.6096343994140625\n",
      "Epoch: 1000, Loss: 6.609111309051514\n",
      "Epoch: 1000, Loss: 6.608593940734863\n",
      "Epoch: 1000, Loss: 6.608081340789795\n",
      "Epoch: 1000, Loss: 6.607574462890625\n",
      "Epoch: 1000, Loss: 6.607072353363037\n",
      "Epoch: 1000, Loss: 6.6065754890441895\n",
      "Epoch: 1000, Loss: 6.606083393096924\n",
      "Epoch: 1000, Loss: 6.60559606552124\n",
      "Epoch: 1000, Loss: 6.605114459991455\n",
      "Epoch: 1000, Loss: 6.604637145996094\n",
      "Epoch: 1000, Loss: 6.604165077209473\n",
      "Epoch: 1000, Loss: 6.603697299957275\n",
      "Epoch: 1000, Loss: 6.603235244750977\n",
      "Epoch: 1000, Loss: 6.602777481079102\n",
      "Epoch: 1000, Loss: 6.60232400894165\n",
      "Epoch: 1000, Loss: 6.601874828338623\n",
      "Epoch: 1000, Loss: 6.601430416107178\n",
      "Epoch: 1000, Loss: 6.6009907722473145\n",
      "Epoch: 1000, Loss: 6.600555419921875\n",
      "Epoch: 1000, Loss: 6.600124359130859\n",
      "Epoch: 1000, Loss: 6.599697589874268\n",
      "Epoch: 1000, Loss: 6.599275588989258\n",
      "Epoch: 1000, Loss: 6.598857402801514\n",
      "Epoch: 1000, Loss: 6.598443508148193\n",
      "Epoch: 1000, Loss: 6.598033428192139\n",
      "Epoch: 1000, Loss: 6.597628593444824\n",
      "Epoch: 1000, Loss: 6.597227573394775\n",
      "Epoch: 1000, Loss: 6.59683084487915\n",
      "Epoch: 1000, Loss: 6.596437931060791\n",
      "Epoch: 1000, Loss: 6.596048831939697\n",
      "Epoch: 1000, Loss: 6.595664024353027\n",
      "Epoch: 1000, Loss: 6.595283508300781\n",
      "Epoch: 1000, Loss: 6.594906330108643\n",
      "Epoch: 1000, Loss: 6.594532489776611\n",
      "Epoch: 1000, Loss: 6.594163417816162\n",
      "Epoch: 1000, Loss: 6.59379768371582\n",
      "Epoch: 1000, Loss: 6.593435287475586\n",
      "Epoch: 1000, Loss: 6.593076229095459\n",
      "Epoch: 1000, Loss: 6.592720985412598\n",
      "Epoch: 1000, Loss: 6.5923686027526855\n",
      "Epoch: 1000, Loss: 6.592021465301514\n",
      "Epoch: 1000, Loss: 6.591681003570557\n",
      "Epoch: 1000, Loss: 6.591339111328125\n",
      "Epoch: 1000, Loss: 6.590999126434326\n",
      "Epoch: 1000, Loss: 6.590662956237793\n",
      "Epoch: 1000, Loss: 6.590328693389893\n",
      "Epoch: 1000, Loss: 6.589998245239258\n",
      "Epoch: 1000, Loss: 6.589670181274414\n",
      "Epoch: 1000, Loss: 6.589344501495361\n",
      "Epoch: 1000, Loss: 6.589021682739258\n",
      "Epoch: 1000, Loss: 6.5887017250061035\n",
      "Epoch: 1000, Loss: 6.588384628295898\n",
      "Epoch: 1000, Loss: 6.588069915771484\n",
      "Epoch: 1000, Loss: 6.587758541107178\n",
      "Epoch: 1000, Loss: 6.587449550628662\n",
      "Epoch: 1000, Loss: 6.587143421173096\n",
      "Epoch: 1000, Loss: 6.5868401527404785\n",
      "Epoch: 1000, Loss: 6.5865397453308105\n",
      "Epoch: 1000, Loss: 6.586240768432617\n",
      "Epoch: 1000, Loss: 6.585946559906006\n",
      "Epoch: 1000, Loss: 6.585658073425293\n",
      "Epoch: 1000, Loss: 6.585370063781738\n",
      "Epoch: 1000, Loss: 6.585081577301025\n",
      "Epoch: 1000, Loss: 6.5847978591918945\n",
      "Epoch: 1000, Loss: 6.584514617919922\n",
      "Epoch: 1000, Loss: 6.584236145019531\n",
      "Epoch: 1000, Loss: 6.58396053314209\n",
      "Epoch: 1000, Loss: 6.583685398101807\n",
      "Epoch: 1000, Loss: 6.583412170410156\n",
      "Epoch: 1000, Loss: 6.583141326904297\n",
      "Epoch: 1000, Loss: 6.58287239074707\n",
      "Epoch: 1000, Loss: 6.582605838775635\n",
      "Epoch: 1000, Loss: 6.582341194152832\n",
      "Epoch: 1000, Loss: 6.582078456878662\n",
      "Epoch: 1000, Loss: 6.581817626953125\n",
      "Epoch: 1000, Loss: 6.581559181213379\n",
      "Epoch: 1000, Loss: 6.581302642822266\n",
      "Epoch: 1000, Loss: 6.581048011779785\n",
      "Epoch: 1000, Loss: 6.580794811248779\n",
      "Epoch: 1000, Loss: 6.580544471740723\n",
      "Epoch: 1000, Loss: 6.580295085906982\n",
      "Epoch: 1000, Loss: 6.580048084259033\n",
      "Epoch: 1000, Loss: 6.579802513122559\n",
      "Epoch: 1000, Loss: 6.579558849334717\n",
      "Epoch: 1000, Loss: 6.579317092895508\n",
      "Epoch: 1000, Loss: 6.579077243804932\n",
      "Epoch: 1000, Loss: 6.578839302062988\n",
      "Epoch: 1000, Loss: 6.578603267669678\n",
      "Epoch: 1000, Loss: 6.578369140625\n",
      "Epoch: 1000, Loss: 6.578136444091797\n",
      "Epoch: 1000, Loss: 6.577906131744385\n",
      "Epoch: 1000, Loss: 6.577677249908447\n",
      "Epoch: 1000, Loss: 6.577449798583984\n",
      "Epoch: 1000, Loss: 6.577224254608154\n",
      "Epoch: 1000, Loss: 6.577000617980957\n",
      "Epoch: 1000, Loss: 6.576777935028076\n",
      "Epoch: 1000, Loss: 6.576557159423828\n",
      "Epoch: 1000, Loss: 6.576337814331055\n",
      "Epoch: 1000, Loss: 6.576120376586914\n",
      "Epoch: 1000, Loss: 6.575904369354248\n",
      "Epoch: 1000, Loss: 6.575690269470215\n",
      "Epoch: 1000, Loss: 6.575477123260498\n",
      "Epoch: 1000, Loss: 6.575265884399414\n",
      "Epoch: 1000, Loss: 6.5750555992126465\n",
      "Epoch: 1000, Loss: 6.57484769821167\n",
      "Epoch: 1000, Loss: 6.574640274047852\n",
      "Epoch: 1000, Loss: 6.574434757232666\n",
      "Epoch: 1000, Loss: 6.574231147766113\n",
      "Epoch: 1000, Loss: 6.574028491973877\n",
      "Epoch: 1000, Loss: 6.573827266693115\n",
      "Epoch: 1000, Loss: 6.573627471923828\n",
      "Epoch: 1000, Loss: 6.573429107666016\n",
      "Epoch: 1000, Loss: 6.5732316970825195\n",
      "Epoch: 1000, Loss: 6.573035717010498\n",
      "Epoch: 1000, Loss: 6.572841644287109\n",
      "Epoch: 1000, Loss: 6.572649002075195\n",
      "Epoch: 1000, Loss: 6.572457313537598\n",
      "Epoch: 1000, Loss: 6.572267055511475\n",
      "Epoch: 1000, Loss: 6.572078227996826\n",
      "Epoch: 1000, Loss: 6.571890830993652\n",
      "Epoch: 1000, Loss: 6.571704864501953\n",
      "Epoch: 1000, Loss: 6.57151985168457\n",
      "Epoch: 1000, Loss: 6.571336269378662\n",
      "Epoch: 1000, Loss: 6.5711541175842285\n",
      "Epoch: 1000, Loss: 6.570972919464111\n",
      "Epoch: 1000, Loss: 6.570793151855469\n",
      "Epoch: 1000, Loss: 6.570614337921143\n",
      "Epoch: 1000, Loss: 6.570436954498291\n",
      "Epoch: 1000, Loss: 6.570260524749756\n",
      "Epoch: 1000, Loss: 6.570085048675537\n",
      "Epoch: 1000, Loss: 6.569911003112793\n",
      "Epoch: 1000, Loss: 6.569737911224365\n",
      "Epoch: 1000, Loss: 6.569565773010254\n",
      "Epoch: 1000, Loss: 6.569395065307617\n",
      "Epoch: 1000, Loss: 6.569225311279297\n",
      "Epoch: 1000, Loss: 6.569056987762451\n",
      "Epoch: 1000, Loss: 6.568889617919922\n",
      "Epoch: 1000, Loss: 6.568723201751709\n",
      "Epoch: 1000, Loss: 6.568558216094971\n",
      "Epoch: 1000, Loss: 6.568394184112549\n",
      "Epoch: 1000, Loss: 6.568231105804443\n",
      "Epoch: 1000, Loss: 6.5680694580078125\n",
      "Epoch: 1000, Loss: 6.56790828704834\n",
      "Epoch: 1000, Loss: 6.567748546600342\n",
      "Epoch: 1000, Loss: 6.56758975982666\n",
      "Epoch: 1000, Loss: 6.567431926727295\n",
      "Epoch: 1000, Loss: 6.567275524139404\n",
      "Epoch: 1000, Loss: 6.56712007522583\n",
      "Epoch: 1000, Loss: 6.566965579986572\n",
      "Epoch: 1000, Loss: 6.566812038421631\n",
      "Epoch: 1000, Loss: 6.566658973693848\n",
      "Epoch: 1000, Loss: 6.566507339477539\n",
      "Epoch: 1000, Loss: 6.566356658935547\n",
      "Epoch: 1000, Loss: 6.566206932067871\n",
      "Epoch: 1000, Loss: 6.566058158874512\n",
      "Epoch: 1000, Loss: 6.565912246704102\n",
      "Epoch: 1000, Loss: 6.565765380859375\n",
      "Epoch: 1000, Loss: 6.565620422363281\n",
      "Epoch: 1000, Loss: 6.565476417541504\n",
      "Epoch: 1000, Loss: 6.565333366394043\n",
      "Epoch: 1000, Loss: 6.565190315246582\n",
      "Epoch: 1000, Loss: 6.565047740936279\n",
      "Epoch: 1000, Loss: 6.564906120300293\n",
      "Epoch: 1000, Loss: 6.564765930175781\n",
      "Epoch: 1000, Loss: 6.564625263214111\n",
      "Epoch: 1000, Loss: 6.564486980438232\n",
      "Epoch: 1000, Loss: 6.564349174499512\n",
      "Epoch: 1000, Loss: 6.564213752746582\n",
      "Epoch: 1000, Loss: 6.564078330993652\n",
      "Epoch: 1000, Loss: 6.563941478729248\n",
      "Epoch: 1000, Loss: 6.563806533813477\n",
      "Epoch: 1000, Loss: 6.5636725425720215\n",
      "Epoch: 1000, Loss: 6.563538551330566\n",
      "Epoch: 1000, Loss: 6.5634050369262695\n",
      "Epoch: 1000, Loss: 6.563272476196289\n",
      "Epoch: 1000, Loss: 6.563140869140625\n",
      "Epoch: 1000, Loss: 6.563009738922119\n",
      "Epoch: 1000, Loss: 6.562878608703613\n",
      "Epoch: 1000, Loss: 6.562748908996582\n",
      "Epoch: 1000, Loss: 6.562619209289551\n",
      "Epoch: 1000, Loss: 6.562490940093994\n",
      "Epoch: 1000, Loss: 6.562363147735596\n",
      "Epoch: 1000, Loss: 6.562236309051514\n",
      "Epoch: 1000, Loss: 6.56210994720459\n",
      "Epoch: 1000, Loss: 6.561984539031982\n",
      "Epoch: 1000, Loss: 6.561859607696533\n",
      "Epoch: 1000, Loss: 6.561734676361084\n",
      "Epoch: 1000, Loss: 6.561611175537109\n",
      "Epoch: 1000, Loss: 6.561488151550293\n",
      "Epoch: 1000, Loss: 6.561365604400635\n",
      "Epoch: 1000, Loss: 6.561244010925293\n",
      "Epoch: 1000, Loss: 6.561123371124268\n",
      "Epoch: 1000, Loss: 6.5610032081604\n",
      "Epoch: 1000, Loss: 6.560883522033691\n",
      "Epoch: 1000, Loss: 6.560764312744141\n",
      "Epoch: 1000, Loss: 6.560645580291748\n",
      "Epoch: 1000, Loss: 6.560527324676514\n",
      "Epoch: 1000, Loss: 6.560410022735596\n",
      "Epoch: 1000, Loss: 6.560293197631836\n",
      "Epoch: 1000, Loss: 6.560177326202393\n",
      "Epoch: 1000, Loss: 6.560061931610107\n",
      "Epoch: 1000, Loss: 6.5599470138549805\n",
      "Epoch: 1000, Loss: 6.5598320960998535\n",
      "Epoch: 1000, Loss: 6.559718132019043\n",
      "Epoch: 1000, Loss: 6.559605121612549\n",
      "Epoch: 1000, Loss: 6.559492111206055\n",
      "Epoch: 1000, Loss: 6.559380054473877\n",
      "Epoch: 1000, Loss: 6.559268951416016\n",
      "Epoch: 1000, Loss: 6.559157848358154\n",
      "Epoch: 1000, Loss: 6.559048175811768\n",
      "Epoch: 1000, Loss: 6.558938503265381\n",
      "Epoch: 1000, Loss: 6.5588297843933105\n",
      "Epoch: 1000, Loss: 6.558721542358398\n",
      "Epoch: 1000, Loss: 6.558612823486328\n",
      "Epoch: 1000, Loss: 6.558505058288574\n",
      "Epoch: 1000, Loss: 6.558398246765137\n",
      "Epoch: 1000, Loss: 6.558291435241699\n",
      "Epoch: 1000, Loss: 6.558185577392578\n",
      "Epoch: 1000, Loss: 6.558080196380615\n",
      "Epoch: 1000, Loss: 6.557975769042969\n",
      "Epoch: 1000, Loss: 6.557871341705322\n",
      "Epoch: 1000, Loss: 6.557767868041992\n",
      "Epoch: 1000, Loss: 6.55766487121582\n",
      "Epoch: 1000, Loss: 6.557562351226807\n",
      "Epoch: 1000, Loss: 6.557460308074951\n",
      "Epoch: 1000, Loss: 6.557359218597412\n",
      "Epoch: 1000, Loss: 6.557258129119873\n",
      "Epoch: 1000, Loss: 6.557157516479492\n",
      "Epoch: 1000, Loss: 6.557056903839111\n",
      "Epoch: 1000, Loss: 6.556957244873047\n",
      "Epoch: 1000, Loss: 6.556858062744141\n",
      "Epoch: 1000, Loss: 6.556758880615234\n",
      "Epoch: 1000, Loss: 6.5566606521606445\n",
      "Epoch: 1000, Loss: 6.556563377380371\n",
      "Epoch: 1000, Loss: 6.556466102600098\n",
      "Epoch: 1000, Loss: 6.556369304656982\n",
      "Epoch: 1000, Loss: 6.556272983551025\n",
      "Epoch: 1000, Loss: 6.556177616119385\n",
      "Epoch: 1000, Loss: 6.556082248687744\n",
      "Epoch: 1000, Loss: 6.55598783493042\n",
      "Epoch: 1000, Loss: 6.555893421173096\n",
      "Epoch: 1000, Loss: 6.555799961090088\n",
      "Epoch: 1000, Loss: 6.55570650100708\n",
      "Epoch: 1000, Loss: 6.555613994598389\n",
      "Epoch: 1000, Loss: 6.5555219650268555\n",
      "Epoch: 1000, Loss: 6.555429935455322\n",
      "Epoch: 1000, Loss: 6.5553388595581055\n",
      "Epoch: 1000, Loss: 6.5552473068237305\n",
      "Epoch: 1000, Loss: 6.555156230926514\n",
      "Epoch: 1000, Loss: 6.555066108703613\n",
      "Epoch: 1000, Loss: 6.554975986480713\n",
      "Epoch: 1000, Loss: 6.554886341094971\n",
      "Epoch: 1000, Loss: 6.554797172546387\n",
      "Epoch: 1000, Loss: 6.554708480834961\n",
      "Epoch: 1000, Loss: 6.554620265960693\n",
      "Epoch: 1000, Loss: 6.554532527923584\n",
      "Epoch: 1000, Loss: 6.554445266723633\n",
      "Epoch: 1000, Loss: 6.55435848236084\n",
      "Epoch: 1000, Loss: 6.554271697998047\n",
      "Epoch: 1000, Loss: 6.55418586730957\n",
      "Epoch: 1000, Loss: 6.554100036621094\n",
      "Epoch: 1000, Loss: 6.554015159606934\n",
      "Epoch: 1000, Loss: 6.553930282592773\n",
      "Epoch: 1000, Loss: 6.5538458824157715\n",
      "Epoch: 1000, Loss: 6.553761959075928\n",
      "Epoch: 1000, Loss: 6.553678512573242\n",
      "Epoch: 1000, Loss: 6.553595542907715\n",
      "Epoch: 1000, Loss: 6.5535125732421875\n",
      "Epoch: 1000, Loss: 6.553430557250977\n",
      "Epoch: 1000, Loss: 6.553348541259766\n",
      "Epoch: 1000, Loss: 6.553267002105713\n",
      "Epoch: 1000, Loss: 6.553185939788818\n",
      "Epoch: 1000, Loss: 6.553105354309082\n",
      "Epoch: 1000, Loss: 6.553024768829346\n",
      "Epoch: 1000, Loss: 6.552945137023926\n",
      "Epoch: 1000, Loss: 6.552865505218506\n",
      "Epoch: 1000, Loss: 6.552786350250244\n",
      "Epoch: 1000, Loss: 6.552707672119141\n",
      "Epoch: 1000, Loss: 6.552628993988037\n",
      "Epoch: 1000, Loss: 6.55255126953125\n",
      "Epoch: 1000, Loss: 6.552473545074463\n",
      "Epoch: 1000, Loss: 6.552396297454834\n",
      "Epoch: 1000, Loss: 6.552319049835205\n",
      "Epoch: 1000, Loss: 6.552242755889893\n",
      "Epoch: 1000, Loss: 6.552165985107422\n",
      "Epoch: 1000, Loss: 6.552089214324951\n",
      "Epoch: 1000, Loss: 6.552013397216797\n",
      "Epoch: 1000, Loss: 6.551937580108643\n",
      "Epoch: 1000, Loss: 6.5518622398376465\n",
      "Epoch: 1000, Loss: 6.551787376403809\n",
      "Epoch: 1000, Loss: 6.551712512969971\n",
      "Epoch: 1000, Loss: 6.551638126373291\n",
      "Epoch: 1000, Loss: 6.5515642166137695\n",
      "Epoch: 1000, Loss: 6.551490783691406\n",
      "Epoch: 1000, Loss: 6.551417350769043\n",
      "Epoch: 1000, Loss: 6.551344394683838\n",
      "Epoch: 1000, Loss: 6.551271915435791\n",
      "Epoch: 1000, Loss: 6.551199436187744\n",
      "Epoch: 1000, Loss: 6.5511274337768555\n",
      "Epoch: 1000, Loss: 6.551055908203125\n",
      "Epoch: 1000, Loss: 6.5509843826293945\n",
      "Epoch: 1000, Loss: 6.550913333892822\n",
      "Epoch: 1000, Loss: 6.550842761993408\n",
      "Epoch: 1000, Loss: 6.550772666931152\n",
      "Epoch: 1000, Loss: 6.5507025718688965\n",
      "Epoch: 1000, Loss: 6.550632476806641\n",
      "Epoch: 1000, Loss: 6.550563335418701\n",
      "Epoch: 1000, Loss: 6.550494194030762\n",
      "Epoch: 1000, Loss: 6.5504255294799805\n",
      "Epoch: 1000, Loss: 6.550356864929199\n",
      "Epoch: 1000, Loss: 6.550288677215576\n",
      "Epoch: 1000, Loss: 6.550220966339111\n",
      "Epoch: 1000, Loss: 6.5501532554626465\n",
      "Epoch: 1000, Loss: 6.55008602142334\n",
      "Epoch: 1000, Loss: 6.550018787384033\n",
      "Epoch: 1000, Loss: 6.549952030181885\n",
      "Epoch: 1000, Loss: 6.5498857498168945\n",
      "Epoch: 1000, Loss: 6.549819469451904\n",
      "Epoch: 1000, Loss: 6.549753665924072\n",
      "Epoch: 1000, Loss: 6.549688339233398\n",
      "Epoch: 1000, Loss: 6.549623012542725\n",
      "Epoch: 1000, Loss: 6.549557685852051\n",
      "Epoch: 1000, Loss: 6.549493312835693\n",
      "Epoch: 1000, Loss: 6.549428939819336\n",
      "Epoch: 1000, Loss: 6.5493645668029785\n",
      "Epoch: 1000, Loss: 6.549300670623779\n",
      "Epoch: 1000, Loss: 6.549237251281738\n",
      "Epoch: 1000, Loss: 6.549173831939697\n",
      "Epoch: 1000, Loss: 6.5491108894348145\n",
      "Epoch: 1000, Loss: 6.549047946929932\n",
      "Epoch: 1000, Loss: 6.548985481262207\n",
      "Epoch: 1000, Loss: 6.548923015594482\n",
      "Epoch: 1000, Loss: 6.548861026763916\n",
      "Epoch: 1000, Loss: 6.548799514770508\n",
      "Epoch: 1000, Loss: 6.5487380027771\n",
      "Epoch: 1000, Loss: 6.548676490783691\n",
      "Epoch: 1000, Loss: 6.548615455627441\n",
      "Epoch: 1000, Loss: 6.54855489730835\n",
      "Epoch: 1000, Loss: 6.548494338989258\n",
      "Epoch: 1000, Loss: 6.548434257507324\n",
      "Epoch: 1000, Loss: 6.548374176025391\n",
      "Epoch: 1000, Loss: 6.548314571380615\n",
      "Epoch: 1000, Loss: 6.54825496673584\n",
      "Epoch: 1000, Loss: 6.548195838928223\n",
      "Epoch: 1000, Loss: 6.5481367111206055\n",
      "Epoch: 1000, Loss: 6.5480780601501465\n",
      "Epoch: 1000, Loss: 6.548019886016846\n",
      "Epoch: 1000, Loss: 6.547961235046387\n",
      "Epoch: 1000, Loss: 6.547903537750244\n",
      "Epoch: 1000, Loss: 6.547845363616943\n",
      "Epoch: 1000, Loss: 6.547788143157959\n",
      "Epoch: 1000, Loss: 6.547730922698975\n",
      "Epoch: 1000, Loss: 6.54767370223999\n",
      "Epoch: 1000, Loss: 6.547616958618164\n",
      "Epoch: 1000, Loss: 6.547560214996338\n",
      "Epoch: 1000, Loss: 6.54750394821167\n",
      "Epoch: 1000, Loss: 6.547447681427002\n",
      "Epoch: 1000, Loss: 6.547391891479492\n",
      "Epoch: 1000, Loss: 6.547336101531982\n",
      "Epoch: 1000, Loss: 6.547280311584473\n",
      "Epoch: 1000, Loss: 6.547224998474121\n",
      "Epoch: 1000, Loss: 6.547170162200928\n",
      "Epoch: 1000, Loss: 6.547115325927734\n",
      "Epoch: 1000, Loss: 6.547060489654541\n",
      "Epoch: 1000, Loss: 6.547006130218506\n",
      "Epoch: 1000, Loss: 6.546952247619629\n",
      "Epoch: 1000, Loss: 6.546897888183594\n",
      "Epoch: 1000, Loss: 6.546844482421875\n",
      "Epoch: 1000, Loss: 6.546790599822998\n",
      "Epoch: 1000, Loss: 6.546736717224121\n",
      "Epoch: 1000, Loss: 6.546683311462402\n",
      "Epoch: 1000, Loss: 6.546629905700684\n",
      "Epoch: 1000, Loss: 6.546576499938965\n",
      "Epoch: 1000, Loss: 6.546523571014404\n",
      "Epoch: 1000, Loss: 6.546471118927002\n",
      "Epoch: 1000, Loss: 6.546418190002441\n",
      "Epoch: 1000, Loss: 6.546366214752197\n",
      "Epoch: 1000, Loss: 6.546313762664795\n",
      "Epoch: 1000, Loss: 6.546261787414551\n",
      "Epoch: 1000, Loss: 6.546210289001465\n",
      "Epoch: 1000, Loss: 6.546158313751221\n",
      "Epoch: 1000, Loss: 6.546107292175293\n",
      "Epoch: 1000, Loss: 6.546055793762207\n",
      "Epoch: 1000, Loss: 6.546004772186279\n",
      "Epoch: 1000, Loss: 6.54595422744751\n",
      "Epoch: 1000, Loss: 6.54590368270874\n",
      "Epoch: 1000, Loss: 6.545853137969971\n",
      "Epoch: 1000, Loss: 6.545803070068359\n",
      "Epoch: 1000, Loss: 6.545753002166748\n",
      "Epoch: 1000, Loss: 6.545702934265137\n",
      "Epoch: 1000, Loss: 6.545653343200684\n",
      "Epoch: 1000, Loss: 6.5456037521362305\n",
      "Epoch: 1000, Loss: 6.5455546379089355\n",
      "Epoch: 1000, Loss: 6.545505523681641\n",
      "Epoch: 1000, Loss: 6.545456409454346\n",
      "Epoch: 1000, Loss: 6.545407772064209\n",
      "Epoch: 1000, Loss: 6.545359134674072\n",
      "Epoch: 1000, Loss: 6.545310974121094\n",
      "Epoch: 1000, Loss: 6.545262813568115\n",
      "Epoch: 1000, Loss: 6.545214653015137\n",
      "Epoch: 1000, Loss: 6.545166969299316\n",
      "Epoch: 1000, Loss: 6.545119285583496\n",
      "Epoch: 1000, Loss: 6.545071601867676\n",
      "Epoch: 1000, Loss: 6.545024394989014\n",
      "Epoch: 1000, Loss: 6.544977188110352\n",
      "Epoch: 1000, Loss: 6.544930458068848\n",
      "Epoch: 1000, Loss: 6.544883728027344\n",
      "Epoch: 1000, Loss: 6.54483699798584\n",
      "Epoch: 1000, Loss: 6.544790267944336\n",
      "Epoch: 1000, Loss: 6.54474401473999\n",
      "Epoch: 1000, Loss: 6.544698238372803\n",
      "Epoch: 1000, Loss: 6.544651985168457\n",
      "Epoch: 1000, Loss: 6.5446062088012695\n",
      "Epoch: 1000, Loss: 6.54456090927124\n",
      "Epoch: 1000, Loss: 6.544515132904053\n",
      "Epoch: 1000, Loss: 6.544469833374023\n",
      "Epoch: 1000, Loss: 6.544425010681152\n",
      "Epoch: 1000, Loss: 6.544379711151123\n",
      "Epoch: 1000, Loss: 6.544334888458252\n",
      "Epoch: 1000, Loss: 6.544290542602539\n",
      "Epoch: 1000, Loss: 6.544245719909668\n",
      "Epoch: 1000, Loss: 6.544201374053955\n",
      "Epoch: 1000, Loss: 6.5441575050354\n",
      "Epoch: 1000, Loss: 6.544113636016846\n",
      "Epoch: 1000, Loss: 6.544069766998291\n",
      "Epoch: 1000, Loss: 6.544025897979736\n",
      "Epoch: 1000, Loss: 6.54398250579834\n",
      "Epoch: 1000, Loss: 6.543939113616943\n",
      "Epoch: 1000, Loss: 6.543895721435547\n",
      "Epoch: 1000, Loss: 6.54385232925415\n",
      "Epoch: 1000, Loss: 6.543809413909912\n",
      "Epoch: 1000, Loss: 6.543766975402832\n",
      "Epoch: 1000, Loss: 6.543724060058594\n",
      "Epoch: 1000, Loss: 6.543681621551514\n",
      "Epoch: 1000, Loss: 6.543639183044434\n",
      "Epoch: 1000, Loss: 6.543597221374512\n",
      "Epoch: 1000, Loss: 6.54355525970459\n",
      "Epoch: 1000, Loss: 6.543513298034668\n",
      "Epoch: 1000, Loss: 6.543471336364746\n",
      "Epoch: 1000, Loss: 6.543429851531982\n",
      "Epoch: 1000, Loss: 6.543388366699219\n",
      "Epoch: 1000, Loss: 6.543346881866455\n",
      "Epoch: 1000, Loss: 6.54330587387085\n",
      "Epoch: 1000, Loss: 6.543264865875244\n",
      "Epoch: 1000, Loss: 6.543223857879639\n",
      "Epoch: 1000, Loss: 6.543182849884033\n",
      "Epoch: 1000, Loss: 6.543142318725586\n",
      "Epoch: 1000, Loss: 6.543101787567139\n",
      "Epoch: 1000, Loss: 6.543061256408691\n",
      "Epoch: 1000, Loss: 6.543021202087402\n",
      "Epoch: 1000, Loss: 6.542981147766113\n",
      "Epoch: 1000, Loss: 6.542941093444824\n",
      "Epoch: 1000, Loss: 6.542901515960693\n",
      "Epoch: 1000, Loss: 6.542861461639404\n",
      "Epoch: 1000, Loss: 6.542821884155273\n",
      "Epoch: 1000, Loss: 6.542782783508301\n",
      "Epoch: 1000, Loss: 6.54274320602417\n",
      "Epoch: 1000, Loss: 6.542704105377197\n",
      "Epoch: 1000, Loss: 6.542665004730225\n",
      "Epoch: 1000, Loss: 6.54262638092041\n",
      "Epoch: 1000, Loss: 6.542587757110596\n",
      "Epoch: 1000, Loss: 6.542548656463623\n",
      "Epoch: 1000, Loss: 6.542510509490967\n",
      "Epoch: 1000, Loss: 6.542471885681152\n",
      "Epoch: 1000, Loss: 6.542433738708496\n",
      "Epoch: 1000, Loss: 6.54239559173584\n",
      "Epoch: 1000, Loss: 6.542357444763184\n",
      "Epoch: 1000, Loss: 6.5423197746276855\n",
      "Epoch: 1000, Loss: 6.5422821044921875\n",
      "Epoch: 1000, Loss: 6.5422444343566895\n",
      "Epoch: 1000, Loss: 6.542206764221191\n",
      "Epoch: 1000, Loss: 6.542169570922852\n",
      "Epoch: 1000, Loss: 6.542132377624512\n",
      "Epoch: 1000, Loss: 6.542095184326172\n",
      "Epoch: 1000, Loss: 6.542057991027832\n",
      "Epoch: 1000, Loss: 6.54202127456665\n",
      "Epoch: 1000, Loss: 6.5419840812683105\n",
      "Epoch: 1000, Loss: 6.541947841644287\n",
      "Epoch: 1000, Loss: 6.5419111251831055\n",
      "Epoch: 1000, Loss: 6.541874408721924\n",
      "Epoch: 1000, Loss: 6.5418381690979\n",
      "Epoch: 1000, Loss: 6.541801929473877\n",
      "Epoch: 1000, Loss: 6.541766166687012\n",
      "Epoch: 1000, Loss: 6.541729927062988\n",
      "Epoch: 1000, Loss: 6.541694164276123\n",
      "Epoch: 1000, Loss: 6.5416579246521\n",
      "Epoch: 1000, Loss: 6.541622161865234\n",
      "Epoch: 1000, Loss: 6.541586399078369\n",
      "Epoch: 1000, Loss: 6.541550636291504\n",
      "Epoch: 1000, Loss: 6.541514873504639\n",
      "Epoch: 1000, Loss: 6.541479110717773\n",
      "Epoch: 1000, Loss: 6.541443824768066\n",
      "Epoch: 1000, Loss: 6.541408538818359\n",
      "Epoch: 1000, Loss: 6.541373252868652\n",
      "Epoch: 1000, Loss: 6.541337966918945\n",
      "Epoch: 1000, Loss: 6.5413031578063965\n",
      "Epoch: 1000, Loss: 6.541268348693848\n",
      "Epoch: 1000, Loss: 6.541233539581299\n",
      "Epoch: 1000, Loss: 6.54119873046875\n",
      "Epoch: 1000, Loss: 6.541164398193359\n",
      "Epoch: 1000, Loss: 6.5411295890808105\n",
      "Epoch: 1000, Loss: 6.54109525680542\n",
      "Epoch: 1000, Loss: 6.541060924530029\n",
      "Epoch: 1000, Loss: 6.541027069091797\n",
      "Epoch: 1000, Loss: 6.540992736816406\n",
      "Epoch: 1000, Loss: 6.540958881378174\n",
      "Epoch: 1000, Loss: 6.540925025939941\n",
      "Epoch: 1000, Loss: 6.540891647338867\n",
      "Epoch: 1000, Loss: 6.540857791900635\n",
      "Epoch: 1000, Loss: 6.5408244132995605\n",
      "Epoch: 1000, Loss: 6.540791034698486\n",
      "Epoch: 1000, Loss: 6.540757656097412\n",
      "Epoch: 1000, Loss: 6.540724277496338\n",
      "Epoch: 1000, Loss: 6.540691375732422\n",
      "Epoch: 1000, Loss: 6.540658473968506\n",
      "Epoch: 1000, Loss: 6.540626049041748\n",
      "Epoch: 1000, Loss: 6.540594100952148\n",
      "Epoch: 1000, Loss: 6.540561199188232\n",
      "Epoch: 1000, Loss: 6.540529727935791\n",
      "Epoch: 1000, Loss: 6.540497779846191\n",
      "Epoch: 1000, Loss: 6.54046630859375\n",
      "Epoch: 1000, Loss: 6.54043436050415\n",
      "Epoch: 1000, Loss: 6.540403842926025\n",
      "Epoch: 1000, Loss: 6.540391445159912\n",
      "Epoch: 1000, Loss: 6.540740489959717\n",
      "Epoch: 1000, Loss: 6.54111385345459\n",
      "Epoch: 1000, Loss: 6.541402339935303\n",
      "Epoch: 1000, Loss: 6.541684150695801\n",
      "Epoch: 1000, Loss: 6.541898250579834\n",
      "Epoch: 1000, Loss: 6.542106628417969\n",
      "Epoch: 1000, Loss: 6.54227352142334\n",
      "Epoch: 1000, Loss: 6.542420387268066\n",
      "Epoch: 1000, Loss: 6.542540550231934\n",
      "Epoch: 1000, Loss: 6.54262638092041\n",
      "Epoch: 1000, Loss: 6.542713642120361\n",
      "Epoch: 1000, Loss: 6.542789936065674\n",
      "Epoch: 1000, Loss: 6.5428571701049805\n",
      "Epoch: 1000, Loss: 6.542910575866699\n",
      "Epoch: 1000, Loss: 6.542961597442627\n",
      "Epoch: 1000, Loss: 6.542997360229492\n",
      "Epoch: 1000, Loss: 6.54302978515625\n",
      "Epoch: 1000, Loss: 6.543055057525635\n",
      "Epoch: 1000, Loss: 6.543071746826172\n",
      "Epoch: 1000, Loss: 6.543082237243652\n",
      "Epoch: 1000, Loss: 6.543088912963867\n",
      "Epoch: 1000, Loss: 6.543093204498291\n",
      "Epoch: 1000, Loss: 6.543092727661133\n",
      "Epoch: 1000, Loss: 6.5430908203125\n",
      "Epoch: 1000, Loss: 6.543088436126709\n",
      "Epoch: 1000, Loss: 6.543084621429443\n",
      "Epoch: 1000, Loss: 6.543075084686279\n",
      "Epoch: 1000, Loss: 6.543076038360596\n",
      "Epoch: 1000, Loss: 6.5431060791015625\n",
      "Epoch: 1000, Loss: 6.543152809143066\n",
      "Epoch: 1000, Loss: 6.543159484863281\n",
      "Epoch: 1000, Loss: 6.543201446533203\n",
      "Epoch: 1000, Loss: 6.543210983276367\n",
      "Epoch: 1000, Loss: 6.543248653411865\n",
      "Epoch: 1000, Loss: 6.543285369873047\n",
      "Epoch: 1000, Loss: 6.543319225311279\n",
      "Epoch: 1000, Loss: 6.54332971572876\n",
      "Epoch: 1000, Loss: 6.543341636657715\n",
      "Epoch: 1000, Loss: 6.54335355758667\n",
      "Epoch: 1000, Loss: 6.543366432189941\n",
      "Epoch: 1000, Loss: 6.5433669090271\n",
      "Epoch: 1000, Loss: 6.543365955352783\n",
      "Epoch: 1000, Loss: 6.543361663818359\n",
      "Epoch: 1000, Loss: 6.543359279632568\n",
      "Epoch: 1000, Loss: 6.543351173400879\n",
      "Epoch: 1000, Loss: 6.543339729309082\n",
      "Epoch: 1000, Loss: 6.543325424194336\n",
      "Epoch: 1000, Loss: 6.543309688568115\n",
      "Epoch: 1000, Loss: 6.543292045593262\n",
      "Epoch: 1000, Loss: 6.543272495269775\n",
      "Epoch: 1000, Loss: 6.543251991271973\n",
      "Epoch: 1000, Loss: 6.543230056762695\n",
      "Epoch: 1000, Loss: 6.543206691741943\n",
      "Epoch: 1000, Loss: 6.543181896209717\n",
      "Epoch: 1000, Loss: 6.543156147003174\n",
      "Epoch: 1000, Loss: 6.543128490447998\n",
      "Epoch: 1000, Loss: 6.543100833892822\n",
      "Epoch: 1000, Loss: 6.543071269989014\n",
      "Epoch: 1000, Loss: 6.543041706085205\n",
      "Epoch: 1000, Loss: 6.54301118850708\n",
      "Epoch: 1000, Loss: 6.542980194091797\n",
      "Epoch: 1000, Loss: 6.5429487228393555\n",
      "Epoch: 1000, Loss: 6.542916297912598\n",
      "Epoch: 1000, Loss: 6.54288387298584\n",
      "Epoch: 1000, Loss: 6.542850494384766\n",
      "Epoch: 1000, Loss: 6.542816638946533\n",
      "Epoch: 1000, Loss: 6.542781829833984\n",
      "Epoch: 1000, Loss: 6.5427470207214355\n",
      "Epoch: 1000, Loss: 6.54271125793457\n",
      "Epoch: 1000, Loss: 6.542675971984863\n",
      "Epoch: 1000, Loss: 6.54263973236084\n",
      "Epoch: 1000, Loss: 6.542603015899658\n",
      "Epoch: 1000, Loss: 6.542566299438477\n",
      "Epoch: 1000, Loss: 6.542529582977295\n",
      "Epoch: 1000, Loss: 6.542492389678955\n",
      "Epoch: 1000, Loss: 6.542454719543457\n",
      "Epoch: 1000, Loss: 6.542417526245117\n",
      "Epoch: 1000, Loss: 6.542379379272461\n",
      "Epoch: 1000, Loss: 6.542341232299805\n",
      "Epoch: 1000, Loss: 6.542303085327148\n",
      "Epoch: 1000, Loss: 6.542264461517334\n",
      "Epoch: 1000, Loss: 6.542226314544678\n",
      "Epoch: 1000, Loss: 6.542187213897705\n",
      "Epoch: 1000, Loss: 6.542148590087891\n",
      "Epoch: 1000, Loss: 6.542109966278076\n",
      "Epoch: 1000, Loss: 6.5420708656311035\n",
      "Epoch: 1000, Loss: 6.542031764984131\n",
      "Epoch: 1000, Loss: 6.541992664337158\n",
      "Epoch: 1000, Loss: 6.5419535636901855\n",
      "Epoch: 1000, Loss: 6.541913986206055\n",
      "Epoch: 1000, Loss: 6.541874408721924\n",
      "Epoch: 1000, Loss: 6.541835308074951\n",
      "Epoch: 1000, Loss: 6.5417962074279785\n",
      "Epoch: 1000, Loss: 6.541756629943848\n",
      "Epoch: 1000, Loss: 6.541717052459717\n",
      "Epoch: 1000, Loss: 6.541677951812744\n",
      "Epoch: 1000, Loss: 6.541638374328613\n",
      "Epoch: 1000, Loss: 6.541599273681641\n",
      "Epoch: 1000, Loss: 6.541560173034668\n",
      "Epoch: 1000, Loss: 6.541521072387695\n",
      "Epoch: 1000, Loss: 6.5414814949035645\n",
      "Epoch: 1000, Loss: 6.541441917419434\n",
      "Epoch: 1000, Loss: 6.541402816772461\n",
      "Epoch: 1000, Loss: 6.541363716125488\n",
      "Epoch: 1000, Loss: 6.541324615478516\n",
      "Epoch: 1000, Loss: 6.541285514831543\n",
      "Epoch: 1000, Loss: 6.54124641418457\n",
      "Epoch: 1000, Loss: 6.541207790374756\n",
      "Epoch: 1000, Loss: 6.541168212890625\n",
      "Epoch: 1000, Loss: 6.541129112243652\n",
      "Epoch: 1000, Loss: 6.54109001159668\n",
      "Epoch: 1000, Loss: 6.541050910949707\n",
      "Epoch: 1000, Loss: 6.541011810302734\n",
      "Epoch: 1000, Loss: 6.54097318649292\n",
      "Epoch: 1000, Loss: 6.540934085845947\n",
      "Epoch: 1000, Loss: 6.540895462036133\n",
      "Epoch: 1000, Loss: 6.540856838226318\n",
      "Epoch: 1000, Loss: 6.540818691253662\n",
      "Epoch: 1000, Loss: 6.540780067443848\n",
      "Epoch: 1000, Loss: 6.540741920471191\n",
      "Epoch: 1000, Loss: 6.540703773498535\n",
      "Epoch: 1000, Loss: 6.540665626525879\n",
      "Epoch: 1000, Loss: 6.5406270027160645\n",
      "Epoch: 1000, Loss: 6.54058837890625\n",
      "Epoch: 1000, Loss: 6.540550231933594\n",
      "Epoch: 1000, Loss: 6.5405120849609375\n",
      "Epoch: 1000, Loss: 6.540473937988281\n",
      "Epoch: 1000, Loss: 6.540435791015625\n",
      "Epoch: 1000, Loss: 6.540397644042969\n",
      "Epoch: 1000, Loss: 6.5403594970703125\n",
      "Epoch: 1000, Loss: 6.5403218269348145\n",
      "Epoch: 1000, Loss: 6.540284156799316\n",
      "Epoch: 1000, Loss: 6.540246486663818\n",
      "Epoch: 1000, Loss: 6.54020881652832\n",
      "Epoch: 1000, Loss: 6.5401716232299805\n",
      "Epoch: 1000, Loss: 6.540133953094482\n",
      "Epoch: 1000, Loss: 6.540096282958984\n",
      "Epoch: 1000, Loss: 6.540058612823486\n",
      "Epoch: 1000, Loss: 6.540020942687988\n",
      "Epoch: 1000, Loss: 6.53998327255249\n",
      "Epoch: 1000, Loss: 6.539945602416992\n",
      "Epoch: 1000, Loss: 6.539908409118652\n",
      "Epoch: 1000, Loss: 6.5398712158203125\n",
      "Epoch: 1000, Loss: 6.539834022521973\n",
      "Epoch: 1000, Loss: 6.539796829223633\n",
      "Epoch: 1000, Loss: 6.539759635925293\n",
      "Epoch: 1000, Loss: 6.539722919464111\n",
      "Epoch: 1000, Loss: 6.5396857261657715\n",
      "Epoch: 1000, Loss: 6.53964900970459\n",
      "Epoch: 1000, Loss: 6.539612293243408\n",
      "Epoch: 1000, Loss: 6.539576053619385\n",
      "Epoch: 1000, Loss: 6.539539337158203\n",
      "Epoch: 1000, Loss: 6.53950309753418\n",
      "Epoch: 1000, Loss: 6.539466857910156\n",
      "Epoch: 1000, Loss: 6.539430618286133\n",
      "Epoch: 1000, Loss: 6.539394378662109\n",
      "Epoch: 1000, Loss: 6.539358139038086\n",
      "Epoch: 1000, Loss: 6.539322376251221\n",
      "Epoch: 1000, Loss: 6.5392866134643555\n",
      "Epoch: 1000, Loss: 6.53925085067749\n",
      "Epoch: 1000, Loss: 6.539215087890625\n",
      "Epoch: 1000, Loss: 6.53917932510376\n",
      "Epoch: 1000, Loss: 6.539144039154053\n",
      "Epoch: 1000, Loss: 6.5391082763671875\n",
      "Epoch: 1000, Loss: 6.5390729904174805\n",
      "Epoch: 1000, Loss: 6.539037704467773\n",
      "Epoch: 1000, Loss: 6.539002418518066\n",
      "Epoch: 1000, Loss: 6.538967609405518\n",
      "Epoch: 1000, Loss: 6.5389323234558105\n",
      "Epoch: 1000, Loss: 6.538897514343262\n",
      "Epoch: 1000, Loss: 6.538862705230713\n",
      "Epoch: 1000, Loss: 6.538827896118164\n",
      "Epoch: 1000, Loss: 6.538793087005615\n",
      "Epoch: 1000, Loss: 6.538758754730225\n",
      "Epoch: 1000, Loss: 6.538724422454834\n",
      "Epoch: 1000, Loss: 6.538689136505127\n",
      "Epoch: 1000, Loss: 6.538654327392578\n",
      "Epoch: 1000, Loss: 6.538619518280029\n",
      "Epoch: 1000, Loss: 6.5385847091674805\n",
      "Epoch: 1000, Loss: 6.538549900054932\n",
      "Epoch: 1000, Loss: 6.538515567779541\n",
      "Epoch: 1000, Loss: 6.538480758666992\n",
      "Epoch: 1000, Loss: 6.538446426391602\n",
      "Epoch: 1000, Loss: 6.538412094116211\n",
      "Epoch: 1000, Loss: 6.53837776184082\n",
      "Epoch: 1000, Loss: 6.53834342956543\n",
      "Epoch: 1000, Loss: 6.538309574127197\n",
      "Epoch: 1000, Loss: 6.538275241851807\n",
      "Epoch: 1000, Loss: 6.538241386413574\n",
      "Epoch: 1000, Loss: 6.538207530975342\n",
      "Epoch: 1000, Loss: 6.538173675537109\n",
      "Epoch: 1000, Loss: 6.538140296936035\n",
      "Epoch: 1000, Loss: 6.538106441497803\n",
      "Epoch: 1000, Loss: 6.5380730628967285\n",
      "Epoch: 1000, Loss: 6.538039207458496\n",
      "Epoch: 1000, Loss: 6.538005828857422\n",
      "Epoch: 1000, Loss: 6.537972450256348\n",
      "Epoch: 1000, Loss: 6.537939548492432\n",
      "Epoch: 1000, Loss: 6.537906169891357\n",
      "Epoch: 1000, Loss: 6.537873268127441\n",
      "Epoch: 1000, Loss: 6.537839889526367\n",
      "Epoch: 1000, Loss: 6.537806987762451\n",
      "Epoch: 1000, Loss: 6.537774085998535\n",
      "Epoch: 1000, Loss: 6.537741661071777\n",
      "Epoch: 1000, Loss: 6.537708759307861\n",
      "Epoch: 1000, Loss: 6.5376763343811035\n",
      "Epoch: 1000, Loss: 6.5376434326171875\n",
      "Epoch: 1000, Loss: 6.53761100769043\n",
      "Epoch: 1000, Loss: 6.537578582763672\n",
      "Epoch: 1000, Loss: 6.537546157836914\n",
      "Epoch: 1000, Loss: 6.5375142097473145\n",
      "Epoch: 1000, Loss: 6.537481784820557\n",
      "Epoch: 1000, Loss: 6.537449836730957\n",
      "Epoch: 1000, Loss: 6.537417888641357\n",
      "Epoch: 1000, Loss: 6.5373854637146\n",
      "Epoch: 1000, Loss: 6.537353992462158\n",
      "Epoch: 1000, Loss: 6.537322044372559\n",
      "Epoch: 1000, Loss: 6.537290096282959\n",
      "Epoch: 1000, Loss: 6.537258625030518\n",
      "Epoch: 1000, Loss: 6.537226676940918\n",
      "Epoch: 1000, Loss: 6.537195205688477\n",
      "Epoch: 1000, Loss: 6.537163734436035\n",
      "Epoch: 1000, Loss: 6.537132263183594\n",
      "Epoch: 1000, Loss: 6.5371012687683105\n",
      "Epoch: 1000, Loss: 6.537069797515869\n",
      "Epoch: 1000, Loss: 6.537038803100586\n",
      "Epoch: 1000, Loss: 6.5370073318481445\n",
      "Epoch: 1000, Loss: 6.536976337432861\n",
      "Epoch: 1000, Loss: 6.536945343017578\n",
      "Epoch: 1000, Loss: 6.536914825439453\n",
      "Epoch: 1000, Loss: 6.53688383102417\n",
      "Epoch: 1000, Loss: 6.536852836608887\n",
      "Epoch: 1000, Loss: 6.536822319030762\n",
      "Epoch: 1000, Loss: 6.536791801452637\n",
      "Epoch: 1000, Loss: 6.536761283874512\n",
      "Epoch: 1000, Loss: 6.536730766296387\n",
      "Epoch: 1000, Loss: 6.536700248718262\n",
      "Epoch: 1000, Loss: 6.536669731140137\n",
      "Epoch: 1000, Loss: 6.53663969039917\n",
      "Epoch: 1000, Loss: 6.536609172821045\n",
      "Epoch: 1000, Loss: 6.536579132080078\n",
      "Epoch: 1000, Loss: 6.536549091339111\n",
      "Epoch: 1000, Loss: 6.5365190505981445\n",
      "Epoch: 1000, Loss: 6.536489009857178\n",
      "Epoch: 1000, Loss: 6.536458969116211\n",
      "Epoch: 1000, Loss: 6.536429405212402\n",
      "Epoch: 1000, Loss: 6.5363993644714355\n",
      "Epoch: 1000, Loss: 6.536369800567627\n",
      "Epoch: 1000, Loss: 6.536340236663818\n",
      "Epoch: 1000, Loss: 6.53631067276001\n",
      "Epoch: 1000, Loss: 6.536281108856201\n",
      "Epoch: 1000, Loss: 6.536251544952393\n",
      "Epoch: 1000, Loss: 6.536221981048584\n",
      "Epoch: 1000, Loss: 6.536192893981934\n",
      "Epoch: 1000, Loss: 6.536163806915283\n",
      "Epoch: 1000, Loss: 6.536134243011475\n",
      "Epoch: 1000, Loss: 6.536105155944824\n",
      "Epoch: 1000, Loss: 6.536076068878174\n",
      "Epoch: 1000, Loss: 6.536046981811523\n",
      "Epoch: 1000, Loss: 6.536018371582031\n",
      "Epoch: 1000, Loss: 6.535989284515381\n",
      "Epoch: 1000, Loss: 6.535960674285889\n",
      "Epoch: 1000, Loss: 6.535931587219238\n",
      "Epoch: 1000, Loss: 6.535902976989746\n",
      "Epoch: 1000, Loss: 6.535874366760254\n",
      "Epoch: 1000, Loss: 6.535845756530762\n",
      "Epoch: 1000, Loss: 6.535817623138428\n",
      "Epoch: 1000, Loss: 6.5357890129089355\n",
      "Epoch: 1000, Loss: 6.535760402679443\n",
      "Epoch: 1000, Loss: 6.535732269287109\n",
      "Epoch: 1000, Loss: 6.535704135894775\n",
      "Epoch: 1000, Loss: 6.535676002502441\n",
      "Epoch: 1000, Loss: 6.535647869110107\n",
      "Epoch: 1000, Loss: 6.535619735717773\n",
      "Epoch: 1000, Loss: 6.5355916023254395\n",
      "Epoch: 1000, Loss: 6.5355634689331055\n",
      "Epoch: 1000, Loss: 6.53553581237793\n",
      "Epoch: 1000, Loss: 6.535507678985596\n",
      "Epoch: 1000, Loss: 6.53548002243042\n",
      "Epoch: 1000, Loss: 6.535452365875244\n",
      "Epoch: 1000, Loss: 6.535424709320068\n",
      "Epoch: 1000, Loss: 6.535397052764893\n",
      "Epoch: 1000, Loss: 6.535369396209717\n",
      "Epoch: 1000, Loss: 6.535342216491699\n",
      "Epoch: 1000, Loss: 6.535314559936523\n",
      "Epoch: 1000, Loss: 6.535287380218506\n",
      "Epoch: 1000, Loss: 6.53525972366333\n",
      "Epoch: 1000, Loss: 6.535232067108154\n",
      "Epoch: 1000, Loss: 6.5352044105529785\n",
      "Epoch: 1000, Loss: 6.535176753997803\n",
      "Epoch: 1000, Loss: 6.535149097442627\n",
      "Epoch: 1000, Loss: 6.535121440887451\n",
      "Epoch: 1000, Loss: 6.535094261169434\n",
      "Epoch: 1000, Loss: 6.535066604614258\n",
      "Epoch: 1000, Loss: 6.53503942489624\n",
      "Epoch: 1000, Loss: 6.5350117683410645\n",
      "Epoch: 1000, Loss: 6.534984588623047\n",
      "Epoch: 1000, Loss: 6.534957408905029\n",
      "Epoch: 1000, Loss: 6.534930229187012\n",
      "Epoch: 1000, Loss: 6.534903049468994\n",
      "Epoch: 1000, Loss: 6.534876346588135\n",
      "Epoch: 1000, Loss: 6.534849166870117\n",
      "Epoch: 1000, Loss: 6.534822463989258\n",
      "Epoch: 1000, Loss: 6.53479528427124\n",
      "Epoch: 1000, Loss: 6.534768581390381\n",
      "Epoch: 1000, Loss: 6.5347418785095215\n",
      "Epoch: 1000, Loss: 6.534715175628662\n",
      "Epoch: 1000, Loss: 6.534688472747803\n",
      "Epoch: 1000, Loss: 6.534661769866943\n",
      "Epoch: 1000, Loss: 6.534635543823242\n",
      "Epoch: 1000, Loss: 6.534608840942383\n",
      "Epoch: 1000, Loss: 6.534582614898682\n",
      "Epoch: 1000, Loss: 6.534555912017822\n",
      "Epoch: 1000, Loss: 6.534529685974121\n",
      "Epoch: 1000, Loss: 6.53450345993042\n",
      "Epoch: 1000, Loss: 6.534477233886719\n",
      "Epoch: 1000, Loss: 6.534451007843018\n",
      "Epoch: 1000, Loss: 6.534425258636475\n",
      "Epoch: 1000, Loss: 6.534399032592773\n",
      "Epoch: 1000, Loss: 6.534372806549072\n",
      "Epoch: 1000, Loss: 6.534347057342529\n",
      "Epoch: 1000, Loss: 6.534321308135986\n",
      "Epoch: 1000, Loss: 6.534295558929443\n",
      "Epoch: 1000, Loss: 6.534269332885742\n",
      "Epoch: 1000, Loss: 6.534243583679199\n",
      "Epoch: 1000, Loss: 6.5342183113098145\n",
      "Epoch: 1000, Loss: 6.5341925621032715\n",
      "Epoch: 1000, Loss: 6.5341668128967285\n",
      "Epoch: 1000, Loss: 6.534141540527344\n",
      "Epoch: 1000, Loss: 6.534115791320801\n",
      "Epoch: 1000, Loss: 6.534090518951416\n",
      "Epoch: 1000, Loss: 6.534065246582031\n",
      "Epoch: 1000, Loss: 6.5340399742126465\n",
      "Epoch: 1000, Loss: 6.534014701843262\n",
      "Epoch: 1000, Loss: 6.533989429473877\n",
      "Epochs: 1000, Loss: 6.533989429473877\n"
     ]
    }
   ],
   "source": [
    "params = TrainParams(\n",
    "    epochs_per_train=1000,\n",
    "    update_threshold=0.6,\n",
    "    max_queue_length=8192,    # Number of game examples to keep to train the neural networks.\n",
    "    num_simulations=25,\n",
    "    arena_compare=2,         # Number of games to play during arena play to evaluate new network.\n",
    "    cpuct=1.0,\n",
    "    checkpoint_dir='./temperature/',\n",
    "    load_model=False,\n",
    "    load_folder_file=('/dev/models/8x100x50', 'best.pth.tar'),\n",
    "    num_iters_for_train_examples_history=4,\n",
    "    num_iterations=2,\n",
    "    num_episodes=2,\n",
    "    temperature_threshold=12\n",
    ")\n",
    "\n",
    "the_model.train(examples, params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "15    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "14    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "13    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "12    .  .  .  .  .  .  .  .  .  .  O  .  .  .  .    \n",
      "11    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "10    .  .  .  .  .  .  .  .  .  .  .  X  .  .  .    \n",
      " 9    .  .  .  .  .  .  .  .  .  .  X  O  .  .  .    \n",
      " 8    .  .  .  .  .  .  .  .  .  O  O  X  .  .  .    \n",
      " 7    .  .  .  .  .  .  .  .  .  .  X  .  .  .  .    \n",
      " 6    .  .  .  .  .  .  .  .  . [X] X  .  .  .  .    \n",
      " 5    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      " 4    .  .  .  .  .  .  .  .  .  .  O  .  .  .  .    \n",
      " 3    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      " 2    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      " 1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    \n",
      "                                                     \n",
      "      A  B  C  D  E  F  G  H  I  J  K  L  M  N  O\n"
     ]
    }
   ],
   "source": [
    "board.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 9 9 9 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 9 9 9 3 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 4 9 9 3 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 3 9 9 3 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 3 9 9 9 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 9 9 9 9 9 9 3 3 3 3 3]\n",
      " [3 3 3 3 9 9 9 9 9 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "p, v = the_model.predict(np.expand_dims(ex[0], axis=0).astype(float))\n",
    "print((p*1000).numpy().reshape((15, 15)).astype(int))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}