{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from domoku.tools import GomokuTools as Gt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_size=7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpaxcqwvvl/gomoku/checkpoints\n",
      "Models can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpaxcqwvvl/gomoku/models\n",
      "Logs can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpaxcqwvvl/gomoku/logs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tempdir = tempfile.mkdtemp()\n",
    "\n",
    "data_dir = Path(os.environ.get('MODELS_DIR', tempdir)) / 'gomoku'\n",
    "models_dir = data_dir / 'models'\n",
    "logs_dir = data_dir / 'logs'\n",
    "cp_dir = data_dir / 'checkpoints'\n",
    "print(f\"Checkpoints can be found in {cp_dir}\")\n",
    "print(f\"Models can be found in {models_dir}\")\n",
    "print(f\"Logs can be found in {logs_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial: Training a Conv Model\n",
    "#### Detecting Lines of Three on a Board of 7x7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling Random Boards"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 7, 2)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.data import new_sample\n",
    "sample = new_sample(board_size=input_size, num_blacks=20, num_whites=0)\n",
    "sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 7, 2)\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Gt.print_bin(sample, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Detection Map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 07:20:14.825970: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.models.heuristic_detector import HeuristicDetector\n",
    "detector = HeuristicDetector(input_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notice the additional dimension for the batch size come and go"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 7, 7), dtype=float32, numpy=\narray([[[0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 1., 0.],\n        [0., 1., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.]]], dtype=float32)>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.floor(detector(np.expand_dims(sample, 0))+.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 7)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(detector(np.expand_dims(sample, 0))).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batches From a Dataset\n",
    "#### Strong Advice: Meticulously observe the shape of all incoming data!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "BATCH_SIZE=4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from notebooks.ml_basics_recap.data import new_sample, new_dataset\n",
    "dataset = new_dataset(100, lambda: new_sample(input_size, 20, 0), detector).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs' shape: (4, 7, 7, 2), Labels' shape: (4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "iterator  = iter(dataset)\n",
    "states, labels = iterator.next()\n",
    "print (f\"Inputs' shape: {states.shape}, Labels' shape: {labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Trainable Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 7, 1)\n",
      "(4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.models import SimpleConvQFunction\n",
    "\n",
    "model_q = SimpleConvQFunction(input_size, n_filters=8, n_layers=4)\n",
    "print(model_q(states).shape)\n",
    "print(np.squeeze(model_q(np.expand_dims(states, 0))).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1024 * 8\n",
    "TEST_SIZE = 1024\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a dataset from the heuristics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_dataset = new_dataset(size=TRAIN_SIZE,\n",
    "                            sampler=lambda: new_sample(board_size=input_size, num_blacks=20, num_whites=0),\n",
    "                            labeler=detector, separate=False).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = new_dataset(size=TEST_SIZE,\n",
    "                           sampler=lambda: new_sample(board_size=input_size, num_blacks=20, num_whites=0),\n",
    "                           labeler=detector, separate=False).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_conv_q_function\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  152       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           multiple                  73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,979\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "Epoch 1, Loss: 0.05559470131993294, Accuracy: 0.23578529059886932,     Test Loss: 0.012457892298698425, Test Accuracy: 0.11161492764949799\n",
      "Epoch 2, Loss: 0.006560128647834063, Accuracy: 0.0809946209192276,     Test Loss: 0.002284080022946, Test Accuracy: 0.04779205843806267\n",
      "Epoch 3, Loss: 0.0007613262278027833, Accuracy: 0.027592139318585396,     Test Loss: 0.0001512787857791409, Test Accuracy: 0.012299545109272003\n",
      "Epoch 4, Loss: 0.00011003809049725533, Accuracy: 0.010489904321730137,     Test Loss: 6.18926205788739e-05, Test Accuracy: 0.007867187261581421\n",
      "Epoch 5, Loss: 5.9469359257491305e-05, Accuracy: 0.007711638696491718,     Test Loss: 4.194669963908382e-05, Test Accuracy: 0.006476626731455326\n",
      "Epoch 6, Loss: 4.1790051909629256e-05, Accuracy: 0.006464522797614336,     Test Loss: 3.153031866531819e-05, Test Accuracy: 0.005615185480564833\n",
      "Epoch 7, Loss: 3.1468167435377836e-05, Accuracy: 0.005609649233520031,     Test Loss: 2.49311669904273e-05, Test Accuracy: 0.004993111360818148\n",
      "Epoch 8, Loss: 2.438492447254248e-05, Accuracy: 0.004938108846545219,     Test Loss: 2.104055238305591e-05, Test Accuracy: 0.0045869979076087475\n",
      "Epoch 9, Loss: 1.8644239389686845e-05, Accuracy: 0.004317896906286478,     Test Loss: 1.6758098354330286e-05, Test Accuracy: 0.004093665163964033\n",
      "Epoch 10, Loss: 1.453754521207884e-05, Accuracy: 0.0038128127343952656,     Test Loss: 1.386107578582596e-05, Test Accuracy: 0.0037230458110570908\n",
      "Epoch 11, Loss: 1.1977768735960126e-05, Accuracy: 0.003460891079157591,     Test Loss: 1.2318027984292712e-05, Test Accuracy: 0.0035097049549221992\n",
      "Epoch 12, Loss: 1.0039874723588582e-05, Accuracy: 0.003168575931340456,     Test Loss: 1.0447713066241704e-05, Test Accuracy: 0.0032322925981134176\n",
      "Epoch 13, Loss: 8.39300082589034e-06, Accuracy: 0.002897067228332162,     Test Loss: 9.22659455682151e-06, Test Accuracy: 0.0030375304631888866\n",
      "Epoch 14, Loss: 7.188265044533182e-06, Accuracy: 0.002681093756109476,     Test Loss: 8.203518518712372e-06, Test Accuracy: 0.0028641780372709036\n",
      "Epoch 15, Loss: 6.223263426363701e-06, Accuracy: 0.0024946467019617558,     Test Loss: 7.5143116191611625e-06, Test Accuracy: 0.0027412238996475935\n",
      "Epoch 16, Loss: 5.427537871582899e-06, Accuracy: 0.0023297076113522053,     Test Loss: 6.625030437135138e-06, Test Accuracy: 0.0025739134289324284\n",
      "Epoch 17, Loss: 4.755433110403828e-06, Accuracy: 0.002180695766583085,     Test Loss: 6.164028491184581e-06, Test Accuracy: 0.002482745563611388\n",
      "Epoch 18, Loss: 4.222203642711975e-06, Accuracy: 0.002054800046607852,     Test Loss: 5.659245289280079e-06, Test Accuracy: 0.0023789166007190943\n",
      "Epoch 19, Loss: 3.7351353512349306e-06, Accuracy: 0.0019326498731970787,     Test Loss: 5.141811925568618e-06, Test Accuracy: 0.002267556032165885\n",
      "Epoch 20, Loss: 3.3127616916317493e-06, Accuracy: 0.0018200991908088326,     Test Loss: 4.726864972326439e-06, Test Accuracy: 0.0021741350647062063\n"
     ]
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.training import Trainer\n",
    "\n",
    "trainer = Trainer(model_q, train_data=train_dataset, test_data=test_dataset,\n",
    "                  logs_dir=logs_dir, models_dir=models_dir, checkpoints_dir=cp_dir)\n",
    "\n",
    "trainer.train(20, custom_train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Inspection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "dataset = new_dataset(10, lambda: new_sample(input_size, 20, 0), detector).batch(BATCH_SIZE)\n",
    "iterator  = iter(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Labels vs Learned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]]], shape=(1, 7, 7), dtype=float32)\n",
      "[[-0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.  0. -0.]\n",
      " [-0. -0. -0. -0. -0.  1.  0.]\n",
      " [-0. -0. -0. -0. -0.  0.  0.]\n",
      " [-0. -0. -0. -0. -0.  1. -0.]\n",
      " [-0. -0. -0. -0. -0.  0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0.]]\n"
     ]
    }
   ],
   "source": [
    "states, labels = iterator.next()\n",
    "pred = np.squeeze(model_q(states))\n",
    "\n",
    "print(tf.floor(labels+.01))\n",
    "print(np.round(pred, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}