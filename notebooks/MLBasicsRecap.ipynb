{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from domoku import tools as gt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "input_size=7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "! env | grep LD_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpahmx4b9i/gomoku/checkpoints\n",
      "Models can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpahmx4b9i/gomoku/models\n",
      "Logs can be found in /var/folders/0s/fny92xb54c50mb90g3l_zmx00000gp/T/tmpahmx4b9i/gomoku/logs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tempdir = tempfile.mkdtemp()\n",
    "\n",
    "data_dir = Path(os.environ.get('MODELS_DIR', tempdir)) / 'gomoku'\n",
    "models_dir = data_dir / 'models'\n",
    "logs_dir = data_dir / 'logs'\n",
    "cp_dir = data_dir / 'checkpoints'\n",
    "print(f\"Checkpoints can be found in {cp_dir}\")\n",
    "print(f\"Models can be found in {models_dir}\")\n",
    "print(f\"Logs can be found in {logs_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial: Training a Conv Model\n",
    "#### Detecting Lines of Three on a Board of 7x7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling Random Boards"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 7, 2)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.data import new_sample\n",
    "sample = new_sample(board_size=input_size, num_blacks=20, num_whites=0)\n",
    "sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 7, 2)\n",
      "[[1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "gt.print_channels(sample, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Detection Map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from notebooks.ml_basics_recap.models.heuristic_detector import HeuristicDetector\n",
    "detector = HeuristicDetector(input_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notice the additional dimension for the batch size come and go"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 7, 7), dtype=float32, numpy=\narray([[[0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.floor(detector(np.expand_dims(sample, 0))+.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 7)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(detector(np.expand_dims(sample, 0))).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batches From a Dataset\n",
    "#### Strong Advice: Meticulously observe the shape of all incoming data!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "BATCH_SIZE=4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from notebooks.ml_basics_recap.data import new_sample, new_dataset\n",
    "dataset = new_dataset(100, lambda: new_sample(input_size, 20, 0), detector).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs' shape: (4, 7, 7, 2), Labels' shape: (4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "iterator  = iter(dataset)\n",
    "states, labels = iterator.next()\n",
    "print (f\"Inputs' shape: {states.shape}, Labels' shape: {labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Trainable Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 7, 1)\n",
      "(4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "from notebooks.ml_basics_recap.models import SimpleConvQFunction\n",
    "\n",
    "model_q = SimpleConvQFunction(input_size, n_filters=8, n_layers=4)\n",
    "print(model_q(states).shape)\n",
    "print(np.squeeze(model_q(np.expand_dims(states, 0))).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1024 * 8\n",
    "TEST_SIZE = 1024\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a dataset from the heuristics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_dataset = new_dataset(size=TRAIN_SIZE,\n",
    "                            sampler=lambda: new_sample(board_size=input_size, num_blacks=20, num_whites=0),\n",
    "                            labeler=detector, separate=False).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = new_dataset(size=TEST_SIZE,\n",
    "                           sampler=lambda: new_sample(board_size=input_size, num_blacks=20, num_whites=0),\n",
    "                           labeler=detector, separate=False).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.MeanSquaredError('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.MeanSquaredError('test_accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "current_time = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "iterator  = iter(train_dataset)\n",
    "x_train, y_train = iterator.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_conv_q_function_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           multiple                  152       \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           multiple                  584       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           multiple                  73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten = tf.keras.layers.Flatten()\n",
    "model = SimpleConvQFunction(input_size, n_filters=8, n_layers=4)\n",
    "labels = model(x_train, training=True)\n",
    "loss = loss_object(y_train, labels)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5398149116663262e-05, Accuracy: 0.0015398148680105805, Test Loss: 5.517965473700315e-05, Test Accuracy: 0.0055179656483232975\n",
      "Epoch 2, Loss: 1.4777041542402003e-05, Accuracy: 0.0014777042670175433, Test Loss: 5.4418786021415144e-05, Test Accuracy: 0.005441878456622362\n",
      "Epoch 3, Loss: 1.4137767720967531e-05, Accuracy: 0.0014137765392661095, Test Loss: 5.313763176673092e-05, Test Accuracy: 0.00531376339495182\n",
      "Epoch 4, Loss: 1.3642261365021113e-05, Accuracy: 0.0013642259873449802, Test Loss: 5.363762466004118e-05, Test Accuracy: 0.005363762378692627\n",
      "Epoch 5, Loss: 1.3071849934931379e-05, Accuracy: 0.0013071851572021842, Test Loss: 5.309767584549263e-05, Test Accuracy: 0.00530976802110672\n",
      "Epoch 6, Loss: 1.2592901839525439e-05, Accuracy: 0.0012592901475727558, Test Loss: 5.292805144563317e-05, Test Accuracy: 0.005292805377393961\n",
      "Epoch 7, Loss: 1.2101817446819041e-05, Accuracy: 0.0012101817410439253, Test Loss: 5.227491055848077e-05, Test Accuracy: 0.00522749125957489\n",
      "Epoch 8, Loss: 1.1712545529007912e-05, Accuracy: 0.0011712547857314348, Test Loss: 5.309941479936242e-05, Test Accuracy: 0.0053099412471055984\n",
      "Epoch 9, Loss: 1.1227104550926015e-05, Accuracy: 0.0011227105278521776, Test Loss: 5.091872299090028e-05, Test Accuracy: 0.0050918725319206715\n",
      "Epoch 10, Loss: 1.085635358322179e-05, Accuracy: 0.0010856353910639882, Test Loss: 5.1481296395650133e-05, Test Accuracy: 0.0051481290720403194\n",
      "Epoch 11, Loss: 1.0530899089644663e-05, Accuracy: 0.001053089858032763, Test Loss: 5.175785190658644e-05, Test Accuracy: 0.005175785161554813\n",
      "Epoch 12, Loss: 1.0117547390109394e-05, Accuracy: 0.0010117547353729606, Test Loss: 4.9602964281803e-05, Test Accuracy: 0.004960296209901571\n",
      "Epoch 13, Loss: 9.803001375985332e-06, Accuracy: 0.0009803000139072537, Test Loss: 5.050784602644853e-05, Test Accuracy: 0.005050784442573786\n",
      "Epoch 14, Loss: 9.42919996305136e-06, Accuracy: 0.0009429201600141823, Test Loss: 4.8453388444613665e-05, Test Accuracy: 0.004845339339226484\n",
      "Epoch 15, Loss: 9.150944606517442e-06, Accuracy: 0.0009150944533757865, Test Loss: 4.8573474487056956e-05, Test Accuracy: 0.004857347346842289\n",
      "Epoch 16, Loss: 8.881063877197448e-06, Accuracy: 0.0008881064131855965, Test Loss: 4.860867920797318e-05, Test Accuracy: 0.004860868211835623\n",
      "Epoch 17, Loss: 8.567230906919576e-06, Accuracy: 0.0008567231707274914, Test Loss: 4.7222038119798526e-05, Test Accuracy: 0.004722203593701124\n",
      "Epoch 18, Loss: 8.368432645511348e-06, Accuracy: 0.0008368433336727321, Test Loss: 4.521013397607021e-05, Test Accuracy: 0.0045210132375359535\n",
      "Epoch 19, Loss: 8.100556442514062e-06, Accuracy: 0.0008100556442514062, Test Loss: 4.472066575544886e-05, Test Accuracy: 0.004472066182643175\n",
      "Epoch 20, Loss: 7.909674422990065e-06, Accuracy: 0.0007909673731774092, Test Loss: 4.446546154213138e-05, Test Accuracy: 0.004446546547114849\n",
      "Epoch 21, Loss: 7.679773261770606e-06, Accuracy: 0.0007679772097617388, Test Loss: 4.308487768867053e-05, Test Accuracy: 0.004308488219976425\n",
      "Epoch 22, Loss: 7.475813617929816e-06, Accuracy: 0.0007475814782083035, Test Loss: 4.123777762288228e-05, Test Accuracy: 0.004123777616769075\n",
      "Epoch 23, Loss: 7.2751622610667255e-06, Accuracy: 0.0007275162497535348, Test Loss: 4.0952072595246136e-05, Test Accuracy: 0.004095207434147596\n",
      "Epoch 24, Loss: 7.11991833668435e-06, Accuracy: 0.0007119917427189648, Test Loss: 3.9675265725236386e-05, Test Accuracy: 0.003967526368796825\n",
      "Epoch 25, Loss: 6.951624072826235e-06, Accuracy: 0.0006951625109650195, Test Loss: 3.934989945264533e-05, Test Accuracy: 0.003934990148991346\n",
      "Epoch 26, Loss: 6.775079782528337e-06, Accuracy: 0.0006775079527869821, Test Loss: 3.735631617018953e-05, Test Accuracy: 0.0037356317043304443\n",
      "Epoch 27, Loss: 6.620075055252528e-06, Accuracy: 0.0006620074855163693, Test Loss: 3.586487582651898e-05, Test Accuracy: 0.0035864876117557287\n",
      "Epoch 28, Loss: 6.48129162073019e-06, Accuracy: 0.000648129265755415, Test Loss: 3.4820121072698385e-05, Test Accuracy: 0.003482012078166008\n",
      "Epoch 29, Loss: 6.36461209069239e-06, Accuracy: 0.000636461132671684, Test Loss: 3.401190406293608e-05, Test Accuracy: 0.003401190508157015\n",
      "Epoch 30, Loss: 6.241727533051744e-06, Accuracy: 0.0006241727969609201, Test Loss: 3.264758925070055e-05, Test Accuracy: 0.0032647589687258005\n",
      "Epoch 31, Loss: 6.1094624470570125e-06, Accuracy: 0.000610946211963892, Test Loss: 3.222832310711965e-05, Test Accuracy: 0.0032228322234004736\n",
      "Epoch 32, Loss: 6.005840077705216e-06, Accuracy: 0.0006005840259604156, Test Loss: 3.007601662829984e-05, Test Accuracy: 0.0030076017137616873\n",
      "Epoch 33, Loss: 5.795759989268845e-06, Accuracy: 0.0005795759498141706, Test Loss: 2.912467061833013e-05, Test Accuracy: 0.002912467112764716\n",
      "Epoch 34, Loss: 5.737447736464674e-06, Accuracy: 0.0005737448809668422, Test Loss: 2.8762324291164987e-05, Test Accuracy: 0.002876232611015439\n",
      "Epoch 35, Loss: 5.625772701023379e-06, Accuracy: 0.0005625773337669671, Test Loss: 2.7871121346834116e-05, Test Accuracy: 0.0027871120255440474\n",
      "Epoch 36, Loss: 5.283355676510837e-06, Accuracy: 0.0005283355130814016, Test Loss: 2.6224990506307222e-05, Test Accuracy: 0.002622499130666256\n",
      "Epoch 37, Loss: 5.211000825511292e-06, Accuracy: 0.000521100009791553, Test Loss: 2.5778470444492996e-05, Test Accuracy: 0.0025778471026569605\n",
      "Epoch 38, Loss: 5.024395250075031e-06, Accuracy: 0.0005024395068176091, Test Loss: 2.5217870643245988e-05, Test Accuracy: 0.0025217868387699127\n",
      "Epoch 39, Loss: 4.805107892025262e-06, Accuracy: 0.0004805107892025262, Test Loss: 2.3833796149119735e-05, Test Accuracy: 0.0023833797313272953\n",
      "Epoch 40, Loss: 4.35830770584289e-06, Accuracy: 0.0004358307342045009, Test Loss: 2.2892567358212546e-05, Test Accuracy: 0.0022892567794770002\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_train, y_train in train_dataset:\n",
    "        train_step(model, optimizer, x_train, y_train)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for x_test, y_test in test_dataset:\n",
    "        test_step(model, x_test, y_test)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(),\n",
    "                           train_accuracy.result()*100,\n",
    "                           test_loss.result(),\n",
    "                           test_accuracy.result()*100))\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "dataset = new_dataset(10, lambda: new_sample(input_size, 20, 0), detector).batch(BATCH_SIZE)\n",
    "iterator  = iter(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Labels vs Learned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 7, 2)\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 1.]\n",
      " [1. 1. 0. 1. 0. 1. 1.]\n",
      " [1. 1. 0. 0. 1. 1. 0.]]\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]]], shape=(1, 7, 7), dtype=float32)\n",
      "[[ 0.   -0.   -0.   -0.01 -0.   -0.   -0.  ]\n",
      " [-0.   -0.    0.   -0.   -0.   -0.   -0.  ]\n",
      " [-0.    0.    0.    0.   -0.    0.   -0.  ]\n",
      " [ 0.    0.   -0.   -0.    0.01  0.    0.  ]\n",
      " [ 0.01  0.   -0.01 -0.    0.01  0.01  0.01]\n",
      " [-0.01  1.    0.01  0.99  0.    0.99 -0.01]\n",
      " [-0.02 -0.01  0.01  0.01 -0.   -0.02  0.02]]\n"
     ]
    }
   ],
   "source": [
    "states, labels = iterator.next()\n",
    "pred = np.squeeze(model(states))\n",
    "\n",
    "Gt.print_bin(states, combine=True)\n",
    "print(tf.floor(labels+.01))\n",
    "print(np.round(pred, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'logs/gradient_tape/20220611-132056/train'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_log_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-7abc59a3f5075467\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-7abc59a3f5075467\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape/20220611-132056/train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}