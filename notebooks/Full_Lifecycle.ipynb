{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The Coach on a full lifecycle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from alphazero.mcts import MCTS\n",
    "from alphazero.coach import Coach\n",
    "from alphazero.gomoku_game import GomokuGame as Game\n",
    "from alphazero.interfaces import TrainParams\n",
    "from alphazero.gomoku_model import NeuralNetAdapter\n",
    "from domoku.policies.maximal_criticality import MaxCriticalityPolicy\n",
    "from domoku.policies.softadvice import MaxInfluencePolicy, MaxInfluencePolicyParams\n",
    "from domoku.policies import softadvice\n",
    "from domoku.constants import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BOARD_SIZE = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 19:22:55.299675: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/wgiersche/.local/share/virtualenvs/DeepGomoku-cXtJ_EtM/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "detector = MaxCriticalityPolicy(BOARD_SIZE)\n",
    "game = Game(15, detector=detector, initial='H8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The contenders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Common Performance Parameters\n",
    "\n",
    "num_simulations=25\n",
    "cpuct = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "############################################################\n",
    "# In the blue corner: The heuristic defender!\n",
    "\n",
    "def given_heuristic_brain():\n",
    "    hard_policy = MaxCriticalityPolicy(board_size=BOARD_SIZE, overconfidence=5.0)\n",
    "    mi_params = MaxInfluencePolicyParams(\n",
    "        board_size=BOARD_SIZE,\n",
    "        sigma=.6,\n",
    "        iota=6,\n",
    "        radial_constr=[.0625, .125, .25, .5],\n",
    "        radial_obstr=[-.0625, -.125, -.25, -.5]\n",
    "    )\n",
    "    policy = MaxInfluencePolicy(mi_params, criticality_model=hard_policy, pov=BLACK)\n",
    "    return softadvice.NeuralNetAdapter(policy)\n",
    "\n",
    "brain = given_heuristic_brain()\n",
    "defender = MCTS(game, brain, cpuct=cpuct, num_simulations=num_simulations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class: <class 'alphazero.gomoku_model.GomokuModel'>\n",
      "\n",
      "Model: \"gomoku_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           multiple                  11648     \n",
      "                                                                 \n",
      " Potential_0 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_1 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_2 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_3 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " Potential_4 (Conv2D)        multiple                  123936    \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 631,371\n",
      "Trainable params: 631,361\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "\n",
    "# In the red corner: A fresh neural network\n",
    "\n",
    "network = NeuralNetAdapter(input_size=17)\n",
    "print(f\"Model class: {type(network.policy)}\\n\")\n",
    "network.policy.summary()\n",
    "challenger = MCTS(game, network, cpuct=cpuct, num_simulations=num_simulations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Coach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "params = TrainParams(\n",
    "    epochs_per_train=10,\n",
    "    update_threshold=0.6,\n",
    "    max_queue_length=8192,    # Number of game examples to keep to train the neural networks.\n",
    "    num_simulations=25,\n",
    "    arena_compare=2,         # Number of games to play during arena play to evaluate new network.\n",
    "    cpuct=1.0,\n",
    "    checkpoint_dir='./temperature/',\n",
    "    load_model=False,\n",
    "    load_folder_file=('/dev/models/8x100x50', 'best.pth.tar'),\n",
    "    num_iters_for_train_examples_history=4,\n",
    "    num_iterations=2,\n",
    "    num_episodes=4,\n",
    "    temperature_threshold=6\n",
    ")\n",
    "coach = Coach(game, params=params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraction 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Self Play: 100%|██████████| 4/4 [00:24<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Challenger to learn from the results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Training: 100%|██████████| 10/10 [01:16<00:00,  7.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, Loss: 7.503915309906006\n",
      "   Challenger meets Defender in the Arena\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arena.play_games (1):   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GomokuGame.get_game_ended() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcoach\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefender\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchallenger\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/Project-Ellie/DeepGomoku/alphazero/coach.py:167\u001B[0m, in \u001B[0;36mCoach.train\u001B[0;34m(self, defender, challenger)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m   Challenger meets Defender in the Arena\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    165\u001B[0m arena \u001B[38;5;241m=\u001B[39m Arena(\u001B[38;5;28;01mlambda\u001B[39;00m x: np\u001B[38;5;241m.\u001B[39margmax(defender\u001B[38;5;241m.\u001B[39mget_action_prob(x, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)),\n\u001B[1;32m    166\u001B[0m               \u001B[38;5;28;01mlambda\u001B[39;00m x: np\u001B[38;5;241m.\u001B[39margmax(challenger\u001B[38;5;241m.\u001B[39mget_action_prob(x, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgame)\n\u001B[0;32m--> 167\u001B[0m defender_wins, challenger_wins, draws \u001B[38;5;241m=\u001B[39m \u001B[43marena\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplay_games\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marena_compare\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;66;03m# Do we have a new champion?\u001B[39;00m\n\u001B[1;32m    170\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW/PREV WINS : \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m / \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m ; DRAWS : \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (challenger_wins, defender_wins, draws))\n",
      "File \u001B[0;32m~/workspace/Project-Ellie/DeepGomoku/alphazero/arena.py:81\u001B[0m, in \u001B[0;36mArena.play_games\u001B[0;34m(self, num, verbose)\u001B[0m\n\u001B[1;32m     79\u001B[0m draws \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(num), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArena.play_games (1)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 81\u001B[0m     game_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplay_game\u001B[49m\u001B[43m(\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m game_result \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     83\u001B[0m         one_won \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/workspace/Project-Ellie/DeepGomoku/alphazero/arena.py:44\u001B[0m, in \u001B[0;36mArena.play_game\u001B[0;34m(self, verbose)\u001B[0m\n\u001B[1;32m     42\u001B[0m board \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgame\u001B[38;5;241m.\u001B[39mget_initial_board()\n\u001B[1;32m     43\u001B[0m it \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_game_ended\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_player\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     45\u001B[0m     it \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "\u001B[0;31mTypeError\u001B[0m: GomokuGame.get_game_ended() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "coach.train(defender, challenger)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}