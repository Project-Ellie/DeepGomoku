{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Synthetic data\n",
    "\n",
    "We create a set of *boards* of size $5 \\times 5$ with 3 channels for each position. The label at each position $(j,k)$ is computed as a function of the channel values $v_{jkl}$ at that position.\n",
    "\n",
    "$$\n",
    "    L_{jk} = \\sum_{l=0}^2 a_l \\cdot (v_{jkl})^{l+1}\n",
    "$$\n",
    "\n",
    "Here, $a_l$ denote arbitrary coefficients defined below. Note that this function is the same for every position. Thus, a sufficiently deep convolutional network with only $1 \\times 1$ kernels should easily learn this function by simultaneously looking at all the positions of any given training board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_data(n):\n",
    "    _batch = np.zeros([n,5,5,3])\n",
    "    _labels = np.zeros([n,5,5,1])\n",
    "    _a=[.9, .3, -.2]\n",
    "    for _i in range(n):\n",
    "        for _x in range(5):\n",
    "            for _y in range(5):\n",
    "                for _l in range(3):\n",
    "                    _v = 2*(random.random()-0.5)\n",
    "                    _batch[_i][_x][_y][_l] = _v\n",
    "                    _labels[_i][_x][_y][0] += _a[_l] * _v**(_l+1)\n",
    "    return _batch, _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "train, labels = create_data(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 5, 5, 3)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Smartly rearranging the dimensions of the first *board* of the batch shows the three $5 \\times 5$ channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.85896927  0.69902529 -0.53124401 -0.20641162  0.61040522]\n",
      "  [-0.06872278  0.76939992  0.03751382  0.04917618  0.95711085]\n",
      "  [-0.59620993  0.30264705  0.15305457 -0.82698051 -0.80078748]\n",
      "  [-0.03169596  0.58075038  0.38751542  0.77750194 -0.68356026]\n",
      "  [-0.84472966  0.63342431  0.72946307 -0.30480892  0.3689736 ]]\n",
      "\n",
      " [[-0.8730583   0.3590971  -0.99766832  0.28599123 -0.77423295]\n",
      "  [-0.82824754 -0.23720669  0.30697065 -0.74464368 -0.70631168]\n",
      "  [-0.04318187  0.04302036 -0.14945129  0.59630714 -0.58375218]\n",
      "  [ 0.77249473 -0.38070552  0.39028454  0.84041692 -0.35273369]\n",
      "  [-0.76712986  0.8356657   0.46770037 -0.68763423 -0.30861735]]\n",
      "\n",
      " [[-0.77026088  0.2825407  -0.19212071  0.72794028  0.24096053]\n",
      "  [-0.9953683   0.19143189  0.66628494 -0.04527839 -0.08705117]\n",
      "  [-0.90661841 -0.68658508 -0.57674072 -0.27628564 -0.5172958 ]\n",
      "  [-0.3305647  -0.20905938  0.97747832  0.93200282 -0.1019259 ]\n",
      "  [ 0.41382766 -0.9423963   0.75783356 -0.76777396 -0.19900385]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.rollaxis(train[0], 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF 2.8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<TensorSliceDataset element_spec=TensorSpec(shape=(5, 5, 3), dtype=tf.float64, name=None)>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train = tf.data.Dataset.from_tensor_slices(train)\n",
    "tf_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<TensorSliceDataset element_spec=TensorSpec(shape=(5, 5, 1), dtype=tf.float64, name=None)>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "tf_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "train_input = tf.data.Dataset.zip((tf_train, tf_labels)).batch(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "train_data, train_labels = next(iter(train_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 5, 5, 3), dtype=float64, numpy=\narray([[[[-8.58969271e-01, -8.73058304e-01, -7.70260878e-01],\n         [ 6.99025289e-01,  3.59097099e-01,  2.82540698e-01],\n         [-5.31244012e-01, -9.97668320e-01, -1.92120712e-01],\n         [-2.06411625e-01,  2.85991231e-01,  7.27940278e-01],\n         [ 6.10405225e-01, -7.74232950e-01,  2.40960527e-01]],\n\n        [[-6.87227781e-02, -8.28247541e-01, -9.95368299e-01],\n         [ 7.69399920e-01, -2.37206694e-01,  1.91431887e-01],\n         [ 3.75138201e-02,  3.06970649e-01,  6.66284936e-01],\n         [ 4.91761772e-02, -7.44643680e-01, -4.52783929e-02],\n         [ 9.57110849e-01, -7.06311684e-01, -8.70511716e-02]],\n\n        [[-5.96209934e-01, -4.31818670e-02, -9.06618405e-01],\n         [ 3.02647054e-01,  4.30203645e-02, -6.86585077e-01],\n         [ 1.53054573e-01, -1.49451288e-01, -5.76740718e-01],\n         [-8.26980514e-01,  5.96307142e-01, -2.76285642e-01],\n         [-8.00787482e-01, -5.83752183e-01, -5.17295802e-01]],\n\n        [[-3.16959647e-02,  7.72494731e-01, -3.30564698e-01],\n         [ 5.80750381e-01, -3.80705522e-01, -2.09059383e-01],\n         [ 3.87515418e-01,  3.90284541e-01,  9.77478318e-01],\n         [ 7.77501935e-01,  8.40416920e-01,  9.32002816e-01],\n         [-6.83560255e-01, -3.52733690e-01, -1.01925902e-01]],\n\n        [[-8.44729661e-01, -7.67129858e-01,  4.13827656e-01],\n         [ 6.33424308e-01,  8.35665696e-01, -9.42396295e-01],\n         [ 7.29463066e-01,  4.67700366e-01,  7.57833562e-01],\n         [-3.04808924e-01, -6.87634228e-01, -7.67773962e-01],\n         [ 3.68973603e-01, -3.08617352e-01, -1.99003854e-01]]],\n\n\n       [[[ 8.44424506e-01, -5.72212690e-01,  1.26303943e-01],\n         [ 3.07498718e-01,  4.66172433e-01, -6.25372229e-02],\n         [-4.05567471e-01,  7.24547678e-01,  1.76218633e-01],\n         [ 3.52674532e-01, -4.25540396e-01,  3.95481871e-01],\n         [ 3.37365058e-01,  6.22754085e-01,  8.31654698e-01]],\n\n        [[-5.27656969e-01,  7.29555371e-01,  1.30011880e-01],\n         [-6.51814566e-01, -3.97747364e-01, -9.93928940e-01],\n         [ 1.12781360e-01, -2.61617812e-01,  9.78505835e-01],\n         [ 6.05581293e-01,  8.15478094e-01, -3.29577031e-01],\n         [ 2.44565991e-02, -9.39987592e-01, -2.56893148e-01]],\n\n        [[ 9.05357782e-01,  4.50992831e-01, -4.56366091e-01],\n         [-8.85344509e-01,  8.15563569e-01, -2.33508619e-01],\n         [-4.54691206e-01,  5.92906669e-01, -5.02114834e-01],\n         [-3.89544443e-01,  9.25314477e-01,  7.95845138e-01],\n         [-7.18482653e-01, -3.00284861e-01,  1.34806308e-02]],\n\n        [[ 3.58590253e-01,  2.25626302e-02,  1.96277757e-01],\n         [ 6.12764678e-01, -8.42978105e-01,  8.45271679e-01],\n         [-1.73307280e-01, -2.68861733e-01, -2.75662786e-01],\n         [ 6.85708383e-01,  9.43112322e-01, -8.30257348e-01],\n         [-7.25849739e-01,  6.65584623e-01,  9.36179695e-02]],\n\n        [[-1.51376053e-01,  7.14181345e-01, -4.87624643e-02],\n         [ 4.30408832e-01,  4.79391247e-01,  6.16012470e-01],\n         [-7.20043397e-01,  3.46981845e-01, -2.12165987e-01],\n         [-6.27532423e-01,  7.45846682e-01, -2.75615734e-01],\n         [-9.21829828e-01, -2.21926982e-01,  4.04628848e-01]]],\n\n\n       [[[ 7.71089862e-01,  6.98745611e-01,  8.46419030e-02],\n         [ 8.57775255e-01, -7.83987642e-01,  2.43923949e-01],\n         [ 4.88140495e-01, -2.04271108e-01,  1.39742257e-01],\n         [ 2.89088866e-01, -8.28478168e-01, -5.97402960e-02],\n         [-5.62230857e-01, -6.49464280e-01, -3.78171799e-01]],\n\n        [[ 3.15700031e-01, -6.52064397e-01,  1.67424153e-01],\n         [-8.56138752e-01, -1.60532731e-01,  2.14200172e-01],\n         [ 2.42935667e-01,  7.53001108e-01, -1.35542346e-02],\n         [ 6.65432114e-03, -7.30251514e-01, -3.99563698e-01],\n         [-4.30229660e-02,  3.40396644e-01, -2.97462415e-01]],\n\n        [[ 2.74974880e-01,  5.72244903e-01,  2.78744087e-01],\n         [-4.31732784e-01,  4.78419446e-01, -6.97587768e-01],\n         [-6.76138907e-01,  3.50229232e-01,  4.99414498e-01],\n         [-6.58776140e-01,  5.58673857e-01,  9.81045643e-01],\n         [ 5.22601330e-01,  9.84892661e-01,  4.60564331e-02]],\n\n        [[ 7.35288061e-01, -4.57151792e-01, -8.68731522e-02],\n         [ 8.09872406e-01, -7.65813735e-01,  3.26188367e-01],\n         [-6.01023927e-01, -9.77614240e-01, -7.46129631e-02],\n         [ 7.91357675e-02, -6.34840827e-01, -5.23033150e-01],\n         [ 1.52113724e-01, -1.90263135e-01,  4.50553020e-01]],\n\n        [[-2.65349923e-01, -1.33083055e-01, -4.08633265e-01],\n         [ 9.34879363e-01,  8.17085785e-01,  9.41649136e-01],\n         [ 6.89632539e-01, -1.07911127e-01,  3.74540164e-01],\n         [ 9.70813805e-01,  1.33677598e-01,  6.53350411e-02],\n         [ 2.58164700e-02, -1.99052275e-01, -3.15958395e-01]]],\n\n\n       [[[ 9.40999596e-01,  1.51208911e-02, -9.66948569e-01],\n         [ 6.20636637e-02, -7.76247648e-01,  2.27422298e-01],\n         [ 8.62025024e-03, -3.45219156e-01,  9.70329564e-01],\n         [ 8.69448152e-01, -4.83061393e-01, -8.94205940e-01],\n         [ 1.09908708e-01, -3.34919246e-01,  8.27872518e-01]],\n\n        [[ 3.24261061e-01,  9.48025853e-01,  3.91987806e-01],\n         [-2.65826812e-01,  1.89822722e-01, -7.75738329e-01],\n         [ 2.99893743e-01,  7.80312907e-01, -2.86311245e-01],\n         [ 2.87112919e-01,  9.28212600e-01, -3.14381204e-01],\n         [ 2.71250573e-01, -4.55348454e-01, -6.04766576e-01]],\n\n        [[-4.09498962e-01,  3.27210374e-01,  3.63778140e-01],\n         [ 7.70005994e-01, -5.04231193e-01, -5.38906071e-04],\n         [-5.31087808e-01, -9.96710195e-01,  2.86898618e-01],\n         [ 3.38012180e-01, -4.34784552e-01,  3.62098699e-01],\n         [ 1.09794886e-02,  6.50381825e-01, -4.00133161e-01]],\n\n        [[ 3.90256144e-01, -9.90436818e-01, -7.36500429e-01],\n         [-4.33493389e-02,  3.59900190e-01,  8.99447877e-01],\n         [ 1.64433313e-01, -5.91434174e-01,  2.06543429e-01],\n         [ 4.76940931e-01, -4.63422038e-01, -2.35096526e-01],\n         [ 3.25004357e-01, -8.14806414e-01,  4.05642337e-01]],\n\n        [[ 3.15835936e-01,  3.52323729e-01,  7.98542275e-01],\n         [-7.27871673e-01, -5.23015409e-01,  4.92720437e-01],\n         [-5.31602745e-01, -3.04549763e-01,  5.10044584e-01],\n         [-5.13297773e-01, -2.91631387e-01,  5.36442239e-01],\n         [-6.59286967e-01,  7.27228783e-01, -8.21837961e-01]]],\n\n\n       [[[ 9.79175258e-01,  7.62017116e-01, -9.48811393e-01],\n         [ 8.80827028e-01,  2.27347557e-01,  6.67279725e-01],\n         [ 9.56454139e-01,  2.03408118e-01,  4.08049012e-01],\n         [-7.05363131e-01, -4.58612613e-01, -5.10434816e-01],\n         [ 2.46396089e-01, -6.13926463e-01, -9.16628023e-01]],\n\n        [[ 4.86599734e-01,  9.79056816e-01, -2.48831425e-01],\n         [-2.50840065e-01,  3.62786800e-01,  6.70375115e-01],\n         [ 9.27106086e-01, -7.86018819e-01,  1.11036076e-01],\n         [ 8.12759055e-01, -7.79488203e-01, -3.47170010e-01],\n         [ 9.88964245e-01, -2.23015787e-01, -2.46982547e-01]],\n\n        [[-3.97564523e-01,  4.83057631e-01,  5.50102442e-01],\n         [ 5.00225667e-01,  6.12588132e-01,  8.68444275e-01],\n         [ 6.52380026e-01,  8.73559907e-01, -8.31104966e-01],\n         [-5.01353089e-01,  1.81378898e-01, -7.84965264e-02],\n         [ 9.22296313e-01, -6.78103562e-01, -3.24159994e-01]],\n\n        [[ 8.68212288e-01, -4.07429050e-02, -2.02789392e-01],\n         [-5.51571382e-01, -5.98845843e-01, -7.46364733e-01],\n         [ 6.05064012e-01, -8.77954987e-02, -2.72317885e-01],\n         [-5.90145836e-01,  4.62080770e-02, -8.34040209e-02],\n         [ 7.61678531e-01,  1.69432053e-01,  3.64631461e-01]],\n\n        [[ 6.85918697e-01,  9.51752750e-01, -2.90875258e-01],\n         [-4.11599124e-01,  6.44721795e-01,  8.56340038e-01],\n         [-4.72963561e-01, -2.64231171e-01, -8.07296365e-01],\n         [ 9.83572171e-01, -6.60520332e-01, -9.89063233e-01],\n         [-6.90778431e-01,  4.38790531e-01, -5.48278225e-01]]],\n\n\n       [[[-8.52248311e-01, -6.83728402e-01, -9.79522116e-01],\n         [ 8.23022240e-01, -6.16465617e-01, -8.48808846e-01],\n         [-6.65029722e-02,  2.83618320e-01, -7.91322929e-02],\n         [ 1.58722154e-01,  6.63534899e-01,  7.05015123e-02],\n         [-1.92509440e-01,  7.64599159e-01, -7.73747562e-01]],\n\n        [[-4.67443392e-01,  2.70502305e-01, -8.62898235e-01],\n         [-7.81605871e-01,  9.79313233e-01,  7.00591710e-01],\n         [ 8.22881213e-01, -5.00123852e-01, -8.22389369e-01],\n         [ 9.66665355e-01, -9.15452179e-01,  8.15622707e-01],\n         [ 2.84101022e-01, -6.63865568e-01,  8.99347466e-01]],\n\n        [[-7.35359263e-01, -5.84895301e-01,  1.33441612e-01],\n         [ 5.97632755e-01, -4.98105598e-01,  6.19975774e-01],\n         [ 7.99870868e-01, -1.53136469e-01,  2.82027884e-01],\n         [-3.48019382e-01,  9.26554594e-02, -8.77990986e-01],\n         [-6.90868874e-01, -4.88661103e-01, -6.91344150e-01]],\n\n        [[ 1.19930505e-01,  1.34880725e-01, -5.67437954e-01],\n         [-2.48351440e-01,  1.18484892e-01, -8.52053435e-01],\n         [-6.00684835e-01, -7.48760943e-01,  3.33302812e-02],\n         [ 5.12342426e-01, -5.45612281e-01, -6.43639424e-01],\n         [ 1.90125013e-01,  7.85833218e-02,  7.82145416e-01]],\n\n        [[ 2.86551006e-01, -4.48732043e-01, -4.41212611e-01],\n         [ 6.44494864e-01,  5.74268170e-01,  9.49167733e-01],\n         [ 8.74323549e-02,  7.90814286e-01, -7.98616105e-01],\n         [ 3.84108754e-01, -7.14994702e-01, -6.92131703e-01],\n         [-2.73025608e-01,  8.97150858e-01,  8.75279258e-01]]],\n\n\n       [[[ 3.48188775e-01,  4.17122146e-01,  9.60171861e-01],\n         [-9.01455925e-01,  4.77237637e-01, -9.43880896e-01],\n         [-1.27636661e-01, -1.61883029e-01,  9.22648363e-01],\n         [ 9.69170775e-01,  6.93902673e-02, -1.39383044e-01],\n         [-9.10764697e-01,  8.41452801e-01,  9.39294521e-01]],\n\n        [[-2.36775524e-01,  5.53300068e-01, -8.47504768e-01],\n         [ 1.23949663e-01,  5.13045131e-01, -8.88653299e-01],\n         [-5.11596801e-01,  2.04296334e-01, -3.60311723e-01],\n         [-9.64187505e-01,  4.77879973e-01, -1.58531056e-01],\n         [ 1.61894519e-01, -9.79882385e-01,  8.99458855e-01]],\n\n        [[ 9.80952555e-01,  2.47505298e-01,  4.76086132e-01],\n         [ 2.23220943e-03,  4.14442410e-01, -2.57264768e-01],\n         [-1.37641137e-02, -6.11469849e-02, -1.55824658e-01],\n         [ 2.73501126e-01, -5.92067791e-02, -3.90881140e-01],\n         [ 9.26205043e-01,  8.69682920e-01,  8.59413889e-01]],\n\n        [[ 6.47883226e-01, -4.72632538e-01, -8.12348838e-01],\n         [-6.36005780e-01, -9.20291391e-01, -1.57208931e-01],\n         [ 3.63795322e-01, -1.92661017e-01,  3.78551690e-01],\n         [-9.81673323e-01, -5.79432089e-01, -5.72181877e-01],\n         [ 7.41184406e-01,  4.52985948e-01,  1.47714901e-01]],\n\n        [[ 1.71101749e-01,  9.85347188e-01, -9.40395727e-01],\n         [-9.07293130e-02, -8.87938422e-01,  4.90676624e-01],\n         [ 8.97852530e-02, -7.56412926e-02,  6.00616403e-01],\n         [ 3.39260626e-01, -6.69628260e-01,  5.93979055e-01],\n         [ 1.98582049e-03, -9.46777115e-01,  7.54366069e-01]]],\n\n\n       [[[-2.20649033e-01, -9.31509176e-01, -8.45822530e-01],\n         [ 7.90391627e-01,  6.34770543e-01, -6.80899424e-01],\n         [-7.08515961e-01, -1.73234751e-01, -4.86388096e-01],\n         [-4.70260877e-01, -7.95152598e-01, -1.10002583e-01],\n         [ 9.14959147e-02, -3.88788320e-01, -8.27232395e-01]],\n\n        [[ 3.10740518e-01, -6.45669430e-02,  3.82002277e-01],\n         [-3.37698572e-01,  3.57482093e-01, -7.75462862e-01],\n         [ 1.02742376e-01, -8.91038383e-01, -2.21569063e-01],\n         [-9.87134157e-01,  6.78537701e-02, -5.09713031e-01],\n         [-9.97642518e-01,  5.01628258e-01,  2.39699152e-03]],\n\n        [[-6.00084864e-01,  5.13111991e-01,  6.23269900e-01],\n         [ 4.29774864e-01, -7.85647995e-01, -6.70112520e-02],\n         [-6.56588840e-01, -4.79273257e-01, -9.22431661e-01],\n         [ 6.70209561e-01, -9.52366009e-01, -6.25727509e-02],\n         [-2.44463463e-01, -8.90311926e-01, -3.55825265e-01]],\n\n        [[-3.07440522e-01, -7.56302631e-01,  4.87295013e-01],\n         [ 2.69223009e-01,  1.20745552e-01, -3.73686466e-01],\n         [-5.94495851e-02,  2.94659247e-01, -4.82187228e-02],\n         [-2.22948658e-01, -7.39034468e-01, -4.27406692e-01],\n         [ 1.87962418e-01, -4.06033536e-02,  5.98744995e-01]],\n\n        [[-5.88425363e-01, -6.30274587e-01, -8.54940935e-01],\n         [-1.52543353e-01, -5.69662525e-01,  8.06317704e-01],\n         [ 6.87529497e-01,  8.50082482e-01, -4.37503604e-01],\n         [ 2.25543615e-01,  1.30980878e-02,  1.55655831e-02],\n         [ 4.17407648e-01, -7.39634597e-01,  3.22709193e-01]]],\n\n\n       [[[ 6.30421918e-01, -6.43721846e-01, -2.43728805e-01],\n         [ 5.89588449e-01, -7.19739300e-01, -7.68597850e-01],\n         [-9.98052428e-01,  5.15610343e-01, -3.33352864e-01],\n         [ 8.91232539e-01,  1.26118507e-01, -5.10618094e-01],\n         [-1.28392599e-01,  3.82231669e-01, -4.94215922e-01]],\n\n        [[-4.78223086e-01, -5.81413678e-01,  3.49857864e-01],\n         [ 3.53043178e-01,  8.40018287e-01,  2.32105824e-01],\n         [-1.57259174e-01,  1.04678805e-01, -5.21741181e-01],\n         [-4.33666324e-01,  2.20034174e-01, -5.55162204e-01],\n         [ 3.50834283e-01,  7.62925246e-01,  9.97007053e-01]],\n\n        [[ 4.59307281e-01,  5.25509391e-01,  9.78371870e-01],\n         [-4.47721354e-02, -1.14282811e-01,  3.54151063e-01],\n         [-6.58144552e-01, -9.10642928e-01, -9.43435127e-01],\n         [-3.48938975e-01, -9.85498908e-01,  2.05994502e-02],\n         [-1.95746246e-01,  4.78415247e-01,  1.91784132e-01]],\n\n        [[ 3.13286844e-01, -3.43338853e-01,  9.40250527e-01],\n         [ 6.91657050e-01,  6.09025057e-01, -4.09538591e-01],\n         [-6.24021275e-01,  9.01351256e-01, -8.72771292e-01],\n         [-5.22437693e-01, -2.28358584e-01,  9.85616929e-02],\n         [ 2.01323688e-01,  4.46636320e-01, -1.60523235e-01]],\n\n        [[-9.44046008e-02, -6.27418946e-01, -7.49979063e-01],\n         [ 7.29954427e-02, -9.91203573e-01,  5.99035201e-01],\n         [ 8.71067734e-01, -5.13192412e-01,  8.29360903e-01],\n         [ 8.11619139e-01,  3.89634161e-01,  9.13444294e-01],\n         [-6.61962403e-01,  9.28996573e-02,  1.22818828e-01]]],\n\n\n       [[[ 1.18087067e-01,  8.09330050e-01, -2.13261069e-01],\n         [ 4.46913599e-03,  2.75516280e-01,  7.62573015e-01],\n         [ 7.39059278e-01,  1.11504460e-01,  9.24447453e-01],\n         [-8.59748466e-01,  3.98615306e-01,  8.66473664e-01],\n         [ 4.83360626e-01,  7.44367757e-01, -7.59528575e-01]],\n\n        [[ 3.92131027e-01, -3.09271848e-01, -1.93610325e-01],\n         [-4.49180232e-01,  4.35881750e-01,  2.70070771e-01],\n         [ 5.60772983e-01, -6.86932561e-01,  8.57126970e-01],\n         [-5.56803394e-01, -7.52367223e-01, -7.53072376e-01],\n         [ 1.92963241e-01, -7.27640089e-01,  7.36563949e-01]],\n\n        [[-5.31104504e-01,  1.57401911e-01,  8.03818975e-01],\n         [-8.97435092e-01, -3.83449940e-01,  6.95458241e-01],\n         [-8.75126003e-01, -8.00435577e-01, -9.24801061e-01],\n         [ 8.94238215e-01,  1.32516094e-01,  2.63513172e-01],\n         [-4.41594872e-01, -2.26377915e-02, -2.65732006e-01]],\n\n        [[-9.83093571e-01, -3.34713918e-01,  3.34586963e-01],\n         [ 4.61368478e-01,  6.07424070e-01, -3.71772024e-01],\n         [-4.18375940e-01,  9.82442489e-01, -8.81770117e-02],\n         [-1.31458153e-02,  1.67672409e-01,  1.21153047e-01],\n         [ 6.42711430e-01,  7.25886821e-01,  4.11491718e-01]],\n\n        [[ 6.92959459e-01,  1.52839193e-01,  7.57862716e-01],\n         [ 5.45789500e-01, -7.76920600e-01,  6.25774705e-01],\n         [ 8.34777571e-01, -1.34230232e-02,  7.78948934e-01],\n         [ 1.74442229e-01,  1.02983142e-01, -4.97297514e-01],\n         [-4.34552406e-01,  7.01016082e-01,  3.84464126e-01]]]])>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 5, 5, 1), dtype=float64, numpy=\narray([[[[-4.53003667e-01],\n         [ 6.63296976e-01],\n         [-1.78098739e-01],\n         [-2.38379848e-01],\n         [ 7.26397572e-01]],\n\n        [[ 3.41181528e-01],\n         [ 7.07936984e-01],\n         [ 2.87420943e-03],\n         [ 2.10625388e-01],\n         [ 1.01119456e+00]],\n\n        [[-3.86989282e-01],\n         [ 3.37668687e-01],\n         [ 1.82818058e-01],\n         [-6.33389816e-01],\n         [-5.90793602e-01]],\n\n        [[ 1.57722425e-01],\n         [ 5.67983774e-01],\n         [ 2.07671441e-01],\n         [ 7.49728940e-01],\n         [-5.77666133e-01]],\n\n        [[-5.97884102e-01],\n         [ 9.46973486e-01],\n         [ 6.35093312e-01],\n         [-4.19587857e-02],\n         [ 3.62225855e-01]]],\n\n\n       [[[ 8.57807287e-01],\n         [ 3.41992783e-01],\n         [-2.08614346e-01],\n         [ 3.59361327e-01],\n         [ 3.04932630e-01]],\n\n        [[-3.15655481e-01],\n         [-3.42792785e-01],\n         [-6.53423262e-02],\n         [ 7.51684319e-01],\n         [ 2.90474627e-01]],\n\n        [[ 8.94849838e-01],\n         [-5.94720407e-01],\n         [-2.78442021e-01],\n         [-1.94540739e-01],\n         [-6.19583578e-01]],\n\n        [[ 3.21371631e-01],\n         [ 6.43885182e-01],\n         [-1.30101041e-01],\n         [ 9.98439605e-01],\n         [-5.20527998e-01]],\n\n        [[ 1.68012395e-02],\n         [ 4.09560921e-01],\n         [-6.10010032e-01],\n         [-3.93705622e-01],\n         [-8.28120901e-01]]],\n\n\n       [[[ 8.40333225e-01],\n         [ 9.53486076e-01],\n         [ 4.51298677e-01],\n         [ 4.66135444e-01],\n         [-3.68649851e-01]],\n\n        [[ 4.10747814e-01],\n         [-7.64759224e-01],\n         [ 3.88745799e-01],\n         [ 1.78727232e-01],\n         [ 1.30441936e-03]],\n\n        [[ 3.41385074e-01],\n         [-2.52000711e-01],\n         [-5.96639140e-01],\n         [-6.88105167e-01],\n         [ 7.61325724e-01]],\n\n        [[ 7.24586708e-01],\n         [ 8.97885155e-01],\n         [-2.54119578e-01],\n         [ 2.20745628e-01],\n         [ 1.29470095e-01]],\n\n        [[-2.19854791e-01],\n         [ 8.74687540e-01],\n         [ 6.13654604e-01],\n         [ 8.79037556e-01],\n         [ 4.14297722e-02]]],\n\n\n       [[[ 1.02778559e+00],\n         [ 2.34272924e-01],\n         [-1.39209610e-01],\n         [ 9.95510006e-01],\n         [ 1.90888287e-02]],\n\n        [[ 5.49414726e-01],\n         [-1.35071127e-01],\n         [ 4.57264862e-01],\n         [ 5.23089624e-01],\n         [ 3.50565961e-01]],\n\n        [[-3.46057160e-01],\n         [ 7.69280124e-01],\n         [-1.84672636e-01],\n         [ 3.51426896e-01],\n         [ 1.49593283e-01]],\n\n        [[ 7.25420467e-01],\n         [-1.45687794e-01],\n         [ 2.51166060e-01],\n         [ 4.96273608e-01],\n         [ 4.78327428e-01]],\n\n        [[ 2.19650692e-01],\n         [-5.96944856e-01],\n         [-4.77154462e-01],\n         [-4.67327762e-01],\n         [-3.23682989e-01]]],\n\n\n       [[[ 1.22629093e+00],\n         [ 7.48827507e-01],\n         [ 8.59632826e-01],\n         [-5.45131044e-01],\n         [ 4.88859635e-01]],\n\n        [[ 7.28586818e-01],\n         [-2.46525470e-01],\n         [ 1.01946936e+00],\n         [ 9.22132380e-01],\n         [ 9.08001838e-01]],\n\n        [[-3.21098265e-01],\n         [ 4.31787020e-01],\n         [ 9.30888832e-01],\n         [-4.41251554e-01],\n         [ 9.74826541e-01]],\n\n        [[ 7.83556938e-01],\n         [-3.05675306e-01],\n         [ 5.50908883e-01],\n         [-5.30374661e-01],\n         [ 6.84426849e-01]],\n\n        [[ 8.93998915e-01],\n         [-3.71333312e-01],\n         [-2.99494336e-01],\n         [ 1.20961053e+00],\n         [-5.30975974e-01]]],\n\n\n       [[[-4.38814963e-01],\n         [ 9.77038331e-01],\n         [-3.56217655e-02],\n         [ 2.74863422e-01],\n         [ 9.47713224e-02]],\n\n        [[-2.70245944e-01],\n         [-4.84503071e-01],\n         [ 9.26870631e-01],\n         [ 1.01289759e+00],\n         [ 2.42423069e-01]],\n\n        [[-5.59667812e-01],\n         [ 5.64642223e-01],\n         [ 7.22432530e-01],\n         [-1.75278873e-01],\n         [-4.84058566e-01]],\n\n        [[ 1.49936694e-01],\n         [-9.55873784e-02],\n         [-3.72430872e-01],\n         [ 6.03744332e-01],\n         [ 7.72693950e-02]],\n\n        [[ 3.35482085e-01],\n         [ 5.07955835e-01],\n         [ 3.68174793e-01],\n         [ 5.65375731e-01],\n         [-1.38371848e-01]]],\n\n\n       [[[ 1.88524913e-01],\n         [-5.74800802e-01],\n         [-2.64097580e-01],\n         [ 8.74239777e-01],\n         [-7.73018446e-01]],\n\n        [[ 4.90807450e-04],\n         [ 3.30874024e-01],\n         [-4.38560563e-01],\n         [-7.98461130e-01],\n         [ 2.88218752e-01]],\n\n        [[ 8.79653214e-01],\n         [ 5.69431638e-02],\n         [-1.05092904e-02],\n         [ 2.59147040e-01],\n         [ 9.33537769e-01]],\n\n        [[ 7.57324886e-01],\n         [-3.17547256e-01],\n         [ 3.27701874e-01],\n         [-7.45317962e-01],\n         [ 7.27980228e-01]],\n\n        [[ 6.11590985e-01],\n         [ 1.31246602e-01],\n         [ 3.91899295e-02],\n         [ 3.97942683e-01],\n         [ 1.84846167e-01]]],\n\n\n       [[[ 1.82751626e-01],\n         [ 8.95368824e-01],\n         [-6.05647986e-01],\n         [-2.33288274e-01],\n         [ 2.40910479e-01]],\n\n        [[ 2.69768341e-01],\n         [-1.72326902e-01],\n         [ 3.32828450e-01],\n         [-8.60554060e-01],\n         [-8.22388997e-01]],\n\n        [[-5.09514957e-01],\n         [ 5.72030392e-01],\n         [-3.65043338e-01],\n         [ 8.75337908e-01],\n         [ 2.67898038e-02]],\n\n        [[-1.28240636e-01],\n         [ 2.57110988e-01],\n         [-2.74349829e-02],\n         [-2.11867790e-02],\n         [ 1.26731281e-01]],\n\n        [[-2.85429641e-01],\n         [-1.44779607e-01],\n         [ 8.52317076e-01],\n         [ 2.03039967e-01],\n         [ 5.33063218e-01]]],\n\n\n       [[[ 6.94588751e-01],\n         [ 7.76845709e-01],\n         [-8.11082268e-01],\n         [ 8.33507825e-01],\n         [-4.75806382e-02]],\n\n        [[-3.37552775e-01],\n         [ 5.26927224e-01],\n         [-1.09840924e-01],\n         [-3.41554419e-01],\n         [ 2.92157733e-01]],\n\n        [[ 3.08922824e-01],\n         [-4.52604896e-02],\n         [-1.75604304e-01],\n         [-2.26843968e-02],\n         [-1.08918085e-01]],\n\n        [[ 1.51072976e-01],\n         [ 7.47502516e-01],\n         [-1.84925754e-01],\n         [-4.54741124e-01],\n         [ 2.41863784e-01]],\n\n        [[ 1.17500154e-01],\n         [ 3.17449317e-01],\n         [ 7.48877457e-01],\n         [ 6.23569641e-01],\n         [-5.93547590e-01]]],\n\n\n       [[[ 3.04722734e-01],\n         [-6.18949380e-02],\n         [ 5.10876193e-01],\n         [-8.56211002e-01],\n         [ 6.88881495e-01]],\n\n        [[ 3.83064142e-01],\n         [-3.51204035e-01],\n         [ 5.20318069e-01],\n         [-2.45889943e-01],\n         [ 2.52583862e-01]],\n\n        [[-5.74434944e-01],\n         [-8.30854794e-01],\n         [-4.37215752e-01],\n         [ 8.06422920e-01],\n         [-3.93528791e-01]],\n\n        [[-8.58665490e-01],\n         [ 5.36197682e-01],\n         [-8.68432545e-02],\n         [-3.75268111e-03],\n         [ 7.22578587e-01]],\n\n        [[ 5.43614875e-01],\n         [ 6.23282314e-01],\n         [ 6.56826632e-01],\n         [ 1.84776478e-01],\n         [-2.55035835e-01]]]])>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (1,1), activation=tf.nn.elu, input_shape=(5,5,3,)),\n",
    "    tf.keras.layers.Conv2D(128, (1,1), activation=tf.nn.elu),\n",
    "    tf.keras.layers.Conv2D(32, (1,1), activation=tf.nn.elu),\n",
    "    tf.keras.layers.Conv2D(1, (1,1), activation=tf.nn.elu)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 5, 5, 1), dtype=float32, numpy=\narray([[[[-0.05334032],\n         [-0.05659205],\n         [ 0.03190439],\n         [ 0.34283587],\n         [-0.06109345]],\n\n        [[-0.28196263],\n         [-0.10404432],\n         [ 0.2533195 ],\n         [-0.04562396],\n         [-0.22309005]],\n\n        [[-0.15591764],\n         [-0.2897539 ],\n         [-0.23770314],\n         [ 0.10933475],\n         [ 0.00936954]],\n\n        [[-0.11108112],\n         [-0.20313597],\n         [ 0.26310945],\n         [ 0.13548249],\n         [ 0.12216482]],\n\n        [[ 0.29931784],\n         [-0.36872143],\n         [ 0.09917687],\n         [-0.17857438],\n         [-0.16309035]]],\n\n\n       [[[-0.1409502 ],\n         [-0.09266061],\n         [ 0.17118774],\n         [ 0.06235463],\n         [ 0.21831003]],\n\n        [[ 0.183496  ],\n         [-0.1606152 ],\n         [ 0.34187418],\n         [-0.22173744],\n         [-0.11282486]],\n\n        [[-0.3001675 ],\n         [ 0.13575557],\n         [-0.06976408],\n         [ 0.384717  ],\n         [ 0.17160602]],\n\n        [[-0.01233947],\n         [ 0.15625061],\n         [-0.06385243],\n         [-0.34834552],\n         [ 0.2177431 ]],\n\n        [[ 0.01933483],\n         [ 0.12262164],\n         [ 0.10638677],\n         [ 0.05642418],\n         [ 0.3483923 ]]],\n\n\n       [[[-0.13318932],\n         [-0.10696489],\n         [-0.06581515],\n         [-0.10345894],\n         [-0.00654215]],\n\n        [[-0.02366257],\n         [ 0.275675  ],\n         [-0.06079221],\n         [-0.1497798 ],\n         [-0.10108078]],\n\n        [[ 0.03813235],\n         [-0.13943905],\n         [ 0.36040765],\n         [ 0.5277439 ],\n         [-0.09907657]],\n\n        [[-0.18981612],\n         [-0.07039279],\n         [ 0.08397604],\n         [-0.20128226],\n         [ 0.1406922 ]],\n\n        [[-0.08554846],\n         [ 0.10456154],\n         [-0.02252066],\n         [-0.17471826],\n         [-0.12875366]]],\n\n\n       [[[-0.41845673],\n         [ 0.05031307],\n         [ 0.35877007],\n         [-0.4090653 ],\n         [ 0.2869084 ]],\n\n        [[ 0.05905009],\n         [-0.20189917],\n         [-0.16023427],\n         [-0.16524243],\n         [-0.26510584]],\n\n        [[ 0.2540108 ],\n         [-0.16850811],\n         [ 0.17909688],\n         [ 0.05265133],\n         [-0.14331698]],\n\n        [[-0.3087874 ],\n         [ 0.35830393],\n         [ 0.0275981 ],\n         [-0.19429415],\n         [ 0.06018819]],\n\n        [[ 0.22154334],\n         [ 0.3206076 ],\n         [ 0.30490148],\n         [ 0.31148502],\n         [-0.12173957]]],\n\n\n       [[[-0.40303868],\n         [ 0.03843938],\n         [-0.06405348],\n         [-0.00952554],\n         [-0.33115447]],\n\n        [[-0.17924255],\n         [ 0.3319139 ],\n         [-0.1606425 ],\n         [-0.27611136],\n         [-0.26949358]],\n\n        [[ 0.32009068],\n         [ 0.18861668],\n         [-0.3465345 ],\n         [ 0.10149722],\n         [-0.2838837 ]],\n\n        [[-0.23985058],\n         [-0.11596054],\n         [-0.22299135],\n         [ 0.1185692 ],\n         [-0.04035556]],\n\n        [[-0.22142649],\n         [ 0.42809007],\n         [-0.15484035],\n         [-0.43825632],\n         [-0.02236068]]],\n\n\n       [[[-0.1079039 ],\n         [-0.39692777],\n         [-0.012312  ],\n         [-0.01101452],\n         [-0.2147314 ]],\n\n        [[-0.17889267],\n         [ 0.4377395 ],\n         [-0.39066303],\n         [ 0.06673864],\n         [ 0.25717652]],\n\n        [[ 0.20053631],\n         [ 0.08764768],\n         [-0.07838488],\n         [-0.21022779],\n         [-0.06764108]],\n\n        [[-0.22572309],\n         [-0.22658384],\n         [ 0.1294256 ],\n         [-0.3140546 ],\n         [ 0.25768474]],\n\n        [[-0.22310108],\n         [ 0.18060756],\n         [-0.26879328],\n         [-0.3026055 ],\n         [ 0.3847721 ]]],\n\n\n       [[[ 0.2670939 ],\n         [-0.0963037 ],\n         [ 0.3810492 ],\n         [-0.23432481],\n         [ 0.5527586 ]],\n\n        [[-0.2280978 ],\n         [-0.30362266],\n         [-0.00266546],\n         [ 0.18314433],\n         [ 0.2593591 ]],\n\n        [[-0.04660064],\n         [-0.0958696 ],\n         [-0.06072432],\n         [-0.20465118],\n         [ 0.0788599 ]],\n\n        [[-0.37048197],\n         [ 0.06966901],\n         [ 0.05725399],\n         [ 0.03531387],\n         [-0.10924584]],\n\n        [[-0.3111301 ],\n         [ 0.16944408],\n         [ 0.21698302],\n         [ 0.13365361],\n         [ 0.23978367]]],\n\n\n       [[[-0.21524131],\n         [-0.33421254],\n         [ 0.00155099],\n         [ 0.0517592 ],\n         [-0.28649938]],\n\n        [[ 0.07323568],\n         [-0.18539906],\n         [-0.11820179],\n         [ 0.06394411],\n         [ 0.24622147]],\n\n        [[ 0.39095202],\n         [-0.13284779],\n         [-0.13955957],\n         [-0.1746822 ],\n         [-0.08091569]],\n\n        [[ 0.21939078],\n         [-0.1945886 ],\n         [-0.00142515],\n         [-0.10480517],\n         [ 0.1905449 ]],\n\n        [[-0.13612545],\n         [ 0.3179717 ],\n         [-0.26052082],\n         [-0.0514586 ],\n         [ 0.01110579]]],\n\n\n       [[[-0.22171926],\n         [-0.35179055],\n         [ 0.13091342],\n         [-0.31740695],\n         [-0.14836389]],\n\n        [[ 0.21908595],\n         [-0.00120091],\n         [-0.15176791],\n         [-0.09240663],\n         [ 0.2652555 ]],\n\n        [[ 0.23927489],\n         [ 0.15520418],\n         [-0.1416288 ],\n         [ 0.05657666],\n         [ 0.1305156 ]],\n\n        [[ 0.27715257],\n         [-0.25868487],\n         [-0.14729416],\n         [ 0.1613484 ],\n         [-0.10430557]],\n\n        [[-0.2225585 ],\n         [ 0.16949278],\n         [ 0.10014143],\n         [ 0.13346876],\n         [ 0.21306905]]],\n\n\n       [[[-0.10268223],\n         [ 0.29880643],\n         [ 0.16042519],\n         [ 0.5224613 ],\n         [-0.3144319 ]],\n\n        [[-0.16558003],\n         [ 0.22514363],\n         [ 0.17783104],\n         [-0.1166774 ],\n         [ 0.21429466]],\n\n        [[ 0.43624467],\n         [ 0.42596862],\n         [-0.08897263],\n         [-0.09983361],\n         [ 0.01239646]],\n\n        [[ 0.33038333],\n         [-0.2149455 ],\n         [ 0.06597341],\n         [ 0.05637837],\n         [-0.0041011 ]],\n\n        [[ 0.1134567 ],\n         [ 0.09458375],\n         [ 0.08919889],\n         [-0.21581244],\n         [ 0.25812477]]]], dtype=float32)>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "loss_object = tf.losses.MeanSquaredError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def loss(_model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = _model(x, training=training)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 0.46725398302078247\n"
     ]
    }
   ],
   "source": [
    "l = loss(model, train_data, train_labels, training=False)\n",
    "print(\"Loss test: {}\".format(l))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def grad(_model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.000032, Accuracy: 0.000%\n",
      "Epoch 001: Loss: 0.000051, Accuracy: 0.000%\n",
      "Epoch 002: Loss: 0.000078, Accuracy: 0.000%\n",
      "Epoch 003: Loss: 0.000115, Accuracy: 0.000%\n",
      "Epoch 004: Loss: 0.000026, Accuracy: 0.000%\n",
      "Epoch 005: Loss: 0.000102, Accuracy: 0.000%\n",
      "Epoch 006: Loss: 0.000047, Accuracy: 0.000%\n",
      "Epoch 007: Loss: 0.000052, Accuracy: 0.000%\n",
      "Epoch 008: Loss: 0.000105, Accuracy: 0.000%\n",
      "Epoch 009: Loss: 0.000081, Accuracy: 0.000%\n",
      "Epoch 010: Loss: 0.000029, Accuracy: 0.000%\n",
      "Epoch 011: Loss: 0.000062, Accuracy: 0.000%\n",
      "Epoch 012: Loss: 0.000069, Accuracy: 0.000%\n",
      "Epoch 013: Loss: 0.008175, Accuracy: 0.000%\n",
      "Epoch 014: Loss: 0.001247, Accuracy: 0.000%\n",
      "Epoch 015: Loss: 0.001091, Accuracy: 0.000%\n",
      "Epoch 016: Loss: 0.000659, Accuracy: 0.000%\n",
      "Epoch 017: Loss: 0.000193, Accuracy: 0.000%\n",
      "Epoch 018: Loss: 0.000105, Accuracy: 0.000%\n",
      "Epoch 019: Loss: 0.000116, Accuracy: 0.000%\n"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    # Training loop - using batches of 32\n",
    "    for x, y in train_input:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    print(\"Epoch {:03d}: Loss: {:.6f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}